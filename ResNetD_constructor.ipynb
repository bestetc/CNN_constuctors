{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ResNet-D Constructor\n",
    "### В пайплайне используется контруктор ResNetD сетей и некоторые трюки, взятые из [статьи](https://arxiv.org/pdf/1812.01187.pdf) Bag of Tricks\n",
    "#### Загрузка и просмотр датасета лежат в [этом ноутбуке](ResNet_constructor.ipynb) \n",
    "- Accuracy на тестовом датасете составляет ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import warnings\n",
    "import torch\n",
    "import torchvision\n",
    "from torch import nn\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from modules import datasets_loader, CNN_blocks, get_optimizer, get_sheduler, train_step, metrics_calc\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Гиперпараметры"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyper params\n",
    "batch_size = 32\n",
    "num_epoch = 365\n",
    "optimizer_type = 'Adam' # 'SGD' or 'Adam'\n",
    "label_smoothing = 0.05 # 0 for disable label_smoothing\n",
    "# neural network architecture\n",
    "resnet_layers = [3,4,8,3]\n",
    "bottleneck = True\n",
    "num_classes = 10\n",
    "# learning rate\n",
    "learning_rate = 0.01 # 0.1 * batch_size / 256\n",
    "warmup_epoch = 5\n",
    "sheduler_type = 'step' # 'cosine' or 'step'\n",
    "sheduler_cycle = 6\n",
    "# misc\n",
    "save_best_model = True\n",
    "save_model_dir = './models/'\n",
    "save_metrics_dir = './metrics/'\n",
    "dataset_path = '../imagenette/imagenette2-320/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Гиперпараметры_обучения\n",
    "- batch_size: кол-во изображений в одном батче. Предел зависит от кол-ва памяти на видеокарте\n",
    "- num_epoch: кол-во эпох обучения. Желательно добавлять к плановому количеству warmup_epoch\n",
    "- optimizer_type: тип оптимизатора, использующегося для обновления весов сети. Может быть 'SGD' или 'Adam'\n",
    "- label_smoothing: параметр сдвига целевой вероятности (epsilon). Подробности в статье Bag of Tricks\n",
    "\n",
    "<b>Архитектура сети:\n",
    " - layers: список с количеством стандартных блоков по слоям\n",
    " - bottleneck: определяет использование стандартных блоков или 'bottleneck' блоков \n",
    " - num_classes: количество предсказываемых классов<br>\n",
    "(!) Сеть ожидает на вход изображение с разрешением 224х224х3\n",
    "\n",
    "<b>Изменения скорости обучения\n",
    " - learning_rate: базовая скорость обучения\n",
    " - warmup_epoch: количество эпох, в течении которых происходит увеличение скорости обучения с 0 до базового значения\n",
    " - sheduler_type: задает стратегию изменения скорости обучения в течении обучения. может быть 'cos' или 'step'\n",
    "    - 'cos': скорость обучения убывает согласно функции косинуса до нуля. В конце цикла скорость обучения возвращается к базовому значению\n",
    "    - 'step': скорость обучения убывает ступенчато, снижаясь в 10 раз. Количество снижений указывается в sheduler_cycle\n",
    " - sheduler_cycle: задает кол-во циклов изменения learning rate. Должно быть меньше или равно num_epoch<br> \n",
    "Для 'cos' интерпритируется как кол-во циклов убывания learning rate с возвратом к стартовому learning rate в начале нового цикла<br>\n",
    "Для 'step' интерпритируется как кол-во уменьшений learning rate\n",
    "\n",
    "<b>Прочее\n",
    "- save_best_model: нужно ли сохранять лучшую модель в процессе обучения. False приведет к сохранению модели в конце обучения\n",
    "- save_model_dir: путь к папке, в которую сохраняются модели\n",
    "- save_metrics_dir: путь к папке, в которую сохраняются метрики обучения\n",
    "- dataset_path: путь к папке с датасетом"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Примеры стандартных сетей:<br>\n",
    "<b>ResNet-18: </b> <br> \n",
    "model = ResNet_like(layers=[2,2,2,2], bottleneck=False, num_classes=10)\n",
    "\n",
    "<b>ResNet-34: </b> <br> \n",
    "model = ResNet_like(resnet_layers=[3,4,6,3], bottleneck=False, num_classes=10)\n",
    "\n",
    "<b>ResNet-50: </b> <br> \n",
    "model = ResNet_like(resnet_layers=[3,4,6,3], bottleneck=True, num_classes=10)\n",
    "\n",
    "<b>ResNet-101: </b> <br> \n",
    "model = ResNet_like(resnet_layers=[3,4,23,3], bottleneck=True, num_classes=10)\n",
    "\n",
    "<b>ResNet-152: </b> <br> \n",
    "model = ResNet_like(resnet_layers=[3,8,36,3], bottleneck=True, num_classes=10)\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Название модели</b><br>\n",
    "Создаем название модели, которое будет фигурировать в названии сохраненных файлов метрики и модели<br>\n",
    "Название модели является производным от гиперпараметров"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ResNet56_Adam_lr0.01_b32_step_sc60'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if bottleneck == True:\n",
    "    model_name = f'ResNet{sum(resnet_layers)*3+2}_{optimizer_type}_lr{learning_rate}_b{batch_size}_{sheduler_type}_sc{(num_epoch-warmup_epoch)//sheduler_cycle}'\n",
    "elif bottleneck == False:\n",
    "    model_name = f'ResNet{sum(resnet_layers)*2+2}_{optimizer_type}_lr{learning_rate}_b{batch_size}_{sheduler_type}_sc{(num_epoch-warmup_epoch)//sheduler_cycle}'\n",
    "model_name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Считаем количество изображения в тренировочном и тестовом датасетах"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9469, 3925)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels_df = pd.read_csv(dataset_path + 'noisy_imagenette.csv')\n",
    "train_img_qty = len(labels_df[labels_df['is_valid'] == False])\n",
    "val_img_qty = len(labels_df[labels_df['is_valid'] == True])\n",
    "train_img_qty, val_img_qty"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Создаем DataLoader попутно предобрабатывая данные\n",
    "- Загрузку датасета можно найти в [ResNet_constructor.ipynb](./ResNet_constructor.ipynb)\n",
    "- Предварительный просмотр данных можно найти в [ResNet_constructor.ipynb](./ResNet_constructor.ipynb)\n",
    "\n",
    "В качетсве аугментаций ипользуется:\n",
    "- уменьшение картинки до разрешения 260*260\n",
    "- вырезка случайного квадрата размером 224*224 (сеть ожидает именно эту размерность)\n",
    "- переворот изображения по горизонтальной оси\n",
    "- нормализация"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import transforms, datasets\n",
    "\n",
    "train_transform = transforms.Compose([\n",
    "        transforms.Resize((260,260)),\n",
    "        transforms.RandomSizedCrop(224),\n",
    "#         transforms.RandomResizedCrop(224, scale=(0.08, 1.0), ratio=(0.75, 1.3333333333333333)),\n",
    "#         transforms.ColorJitter(brightness=0.4, contrast=0.4, saturation=0.4, hue=0.2),\n",
    "        transforms.RandomHorizontalFlip(.5),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                             std=[0.229, 0.224, 0.225])\n",
    "    ])\n",
    "test_transform = transforms.Compose([\n",
    "        transforms.Resize((224,224)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                             std=[0.229, 0.224, 0.225])\n",
    "    ])\n",
    "\n",
    "trainset = datasets.ImageFolder(root=dataset_path + 'train/', transform=train_transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size,\n",
    "                                          shuffle=True)\n",
    "testset = datasets.ImageFolder(root=dataset_path+'val/', transform=test_transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, #batch_size=batch_size,\n",
    "                                         shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Считаем количество батчей в trainloader'e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "297"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_per_epoch = len(trainloader)\n",
    "batch_per_epoch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Конструктор ResNet-like сетей."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(!) Конструктор ожидает на вход изображение с разрешением 224х224х3<br>\n",
    "Выносим в функции сверточные слои для уменьшения количества букв в коде"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv1x1(in_channels, out_channels, stride=1):\n",
    "    return nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=stride, padding=0)\n",
    "\n",
    "def conv3x3(in_channels, out_channels, stride=1,padding=1):\n",
    "    return nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=stride, padding=padding)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Задаем базовые блоки через классы.\n",
    "Класс NormalBlock собирает стандартный ResNet блок с skipconnection'ом\n",
    "Класс BottleneckBlock собирает Bottleneck ResNet блок с skipconnection'ом\n",
    "\n",
    "Каждый класс ожидает параметры:\n",
    " - num_layer - порядковый номер слоя, в котором будет использоваться данных блок. В стандартной ResNet архитектуре блоки используются со второго слоя.\n",
    " - downsample - определяет тип downsampling'а.\n",
    "     - 0 - downsampling не используется\n",
    "     - 1 - downsampling используется в блоке, где уменьшается разрешение и увеличивается кол-во каналов\n",
    "     - -1 - downsampling используется в блоке, где разрешение не уменьшается, но увеличивается кол-во каналов (обычно последний слой)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Класс конструктор ResNet подобных архитектур\n",
    "Данный класс собирает готовую модель из ResNet-блоков"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResNet_like(nn.Module):\n",
    "\n",
    "    def __init__(self, \n",
    "                 layers, \n",
    "                 num_classes,\n",
    "                 bottleneck,\n",
    "                 \n",
    "                 ):\n",
    "        \n",
    "        super(ResNet_like, self).__init__()\n",
    "        self.first = nn.Sequential(\n",
    "            conv3x3(3, 32, stride=2),\n",
    "            nn.BatchNorm2d(32),\n",
    "            conv3x3(32, 32, stride=2),\n",
    "            nn.BatchNorm2d(32),\n",
    "            conv3x3(32, 64),\n",
    "            nn.BatchNorm2d(64))\n",
    "\n",
    "        self.body = nn.Sequential()\n",
    "        if bottleneck == True:\n",
    "            for num, layer in enumerate(layers):\n",
    "                for block in range(layer):\n",
    "                    if block == 0  and num < len(layers) - 1:\n",
    "                        downsample = 1\n",
    "                    elif block == 0 and num == len(layers) - 1:\n",
    "                        downsample = -1\n",
    "                    elif block != 0:  \n",
    "                        downsample = 0\n",
    "                    self.body.add_module(name='block_%d_%d'%(num+2,block+1), module=CNN_blocks.ResNet_D_Bottleneck_Block(num+2, downsample))\n",
    "        elif bottleneck == False:\n",
    "            for num, layer in enumerate(layers):\n",
    "                for block in range(layer):\n",
    "                    if block == 0  and num < len(layers) - 1:\n",
    "                        downsample = 1\n",
    "                    elif block == 0 and num == len(layers) - 1:\n",
    "                        downsample = -1\n",
    "                    elif block != 0:  \n",
    "                        downsample = 0\n",
    "                    self.body.add_module(name='block_%d_%d'%(num+2,block+1), module=CNN_blocks.ResNet_D_Normal_Block(num+2, downsample))\n",
    "                    \n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((1,1))\n",
    "        if bottleneck == True:\n",
    "            self.linear_input = 32*(2**(len(layers)))*4\n",
    "        else:\n",
    "            self.linear_input = 32*(2**(len(layers)))\n",
    "        self.linear = nn.Linear(self.linear_input, num_classes)\n",
    "        \n",
    "    def forward(self, x):\n",
    "\n",
    "        x = self.first(x)\n",
    "#         print('Shape input body:', x.shape)\n",
    "        x = self.body(x)\n",
    "#         print('Shape input avgpool:', x.shape)\n",
    "        x = self.avgpool(x)\n",
    "#         print('Shape input linear:', x.shape)\n",
    "        x = x.view(x.size(0), -1)\n",
    "#         print('Shape input linear:', x.shape)\n",
    "        x = self.linear(x)\n",
    "#         x = self.final(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Функция для подсчета ошибки для label_smoothing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn.modules.loss import _WeightedLoss\n",
    "\n",
    "class SmoothCrossEntropyLoss(_WeightedLoss):\n",
    "    def __init__(self, weight=None, reduction='mean', smoothing=0.0):\n",
    "        super().__init__(weight=weight, reduction=reduction)\n",
    "        self.smoothing = smoothing\n",
    "        self.weight = weight\n",
    "        self.reduction = reduction\n",
    "\n",
    "    def k_one_hot(self, targets:torch.Tensor, n_classes:int, smoothing=0.0):\n",
    "        with torch.no_grad():\n",
    "            targets = torch.empty(size=(targets.size(0), n_classes),\n",
    "                                  device=targets.device) \\\n",
    "                                  .fill_(smoothing /(n_classes-1)) \\\n",
    "                                  .scatter_(1, targets.data.unsqueeze(1), 1.-smoothing)\n",
    "        return targets\n",
    "\n",
    "    def reduce_loss(self, loss):\n",
    "        return loss.mean() if self.reduction == 'mean' else loss.sum() \\\n",
    "        if self.reduction == 'sum' else loss\n",
    "\n",
    "    def forward(self, inputs, targets):\n",
    "        assert 0 <= self.smoothing < 1\n",
    "\n",
    "        targets = self.k_one_hot(targets, inputs.size(-1), self.smoothing)\n",
    "        log_preds = torch.nn.functional.log_softmax(inputs, -1)\n",
    "\n",
    "        if self.weight is not None:\n",
    "            log_preds = log_preds * self.weight.unsqueeze(0)\n",
    "\n",
    "        return self.reduce_loss(-(targets * log_preds).sum(dim=-1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Инициализируем модель с через конструктор"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ResNet_like(layers=resnet_layers, bottleneck=bottleneck, num_classes=num_classes)\n",
    "criterion = SmoothCrossEntropyLoss(smoothing=label_smoothing) #nn.CrossEntropyLoss()\n",
    "if optimizer_type == 'SGD':\n",
    "    optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate, weight_decay=0.0001, momentum=0.9)\n",
    "elif optimizer_type == 'Adam':\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate, betas=(0.95, 0.99), eps=1e-06, weight_decay=0.0001, amsgrad=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Задаем диспетчер изменения скорости обучения"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "if sheduler_type == 'step':\n",
    "    scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=(num_epoch-warmup_epoch)//sheduler_cycle, gamma=0.1)\n",
    "    if warmup_epoch > 0:\n",
    "        scheduler_warmup = torch.optim.lr_scheduler.CyclicLR(optimizer, \n",
    "                                                         base_lr=learning_rate/(batch_per_epoch*warmup_epoch), \n",
    "                                                         max_lr=learning_rate,\n",
    "                                                         step_size_up=((batch_per_epoch+1)*warmup_epoch), # should be batch_per_epoch + 1\n",
    "                                                         step_size_down=0,\n",
    "                                                         cycle_momentum=False,\n",
    "                                                        )    \n",
    "elif sheduler_type == 'cos':\n",
    "    scheduler = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, (num_epoch-warmup_epoch)//sheduler_cycle, eta_min=0)\n",
    "    if warmup_epoch > 0:\n",
    "        scheduler_warmup = torch.optim.lr_scheduler.CyclicLR(optimizer, \n",
    "                                                         base_lr=learning_rate/(batch_per_epoch*warmup_epoch), \n",
    "                                                         max_lr=learning_rate,\n",
    "                                                         step_size_up=((batch_per_epoch+1)*warmup_epoch), # should be batch_per_epoch + 1\n",
    "                                                         step_size_down=0,\n",
    "                                                         cycle_momentum=False,\n",
    "                                                        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ячейча используется для запуска реализации ResNet в библиотеке PyTorch для сравнения с конструктором"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from torchvision.models import resnet34\n",
    "# model = resnet34(num_classes=10)\n",
    "# criterion = nn.CrossEntropyLoss()\n",
    "# optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate, weight_decay=0.0001, momentum=0.9)\n",
    "# # optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate, betas=(0.95, 0.99), eps=1e-06, weight_decay=0.0001, amsgrad=False)\n",
    "# # scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=40, gamma=0.1)\n",
    "# scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, num_epoch, eta_min=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Загружаем модель на видеокарту."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:4\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ResNet_like(\n",
       "  (first): Sequential(\n",
       "    (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "    (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): Conv2d(32, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "    (3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (4): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (5): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (body): Sequential(\n",
       "    (block_2_1): ResNet_D_Bottleneck_Block(\n",
       "      (downsample): Sequential(\n",
       "        (0): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "        (1): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU()\n",
       "    )\n",
       "    (block_2_2): ResNet_D_Bottleneck_Block(\n",
       "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU()\n",
       "    )\n",
       "    (block_2_3): ResNet_D_Bottleneck_Block(\n",
       "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU()\n",
       "    )\n",
       "    (block_3_1): ResNet_D_Bottleneck_Block(\n",
       "      (downsample): Sequential(\n",
       "        (0): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "        (1): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU()\n",
       "    )\n",
       "    (block_3_2): ResNet_D_Bottleneck_Block(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU()\n",
       "    )\n",
       "    (block_3_3): ResNet_D_Bottleneck_Block(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU()\n",
       "    )\n",
       "    (block_3_4): ResNet_D_Bottleneck_Block(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU()\n",
       "    )\n",
       "    (block_4_1): ResNet_D_Bottleneck_Block(\n",
       "      (downsample): Sequential(\n",
       "        (0): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "        (1): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (2): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU()\n",
       "    )\n",
       "    (block_4_2): ResNet_D_Bottleneck_Block(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU()\n",
       "    )\n",
       "    (block_4_3): ResNet_D_Bottleneck_Block(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU()\n",
       "    )\n",
       "    (block_4_4): ResNet_D_Bottleneck_Block(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU()\n",
       "    )\n",
       "    (block_4_5): ResNet_D_Bottleneck_Block(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU()\n",
       "    )\n",
       "    (block_4_6): ResNet_D_Bottleneck_Block(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU()\n",
       "    )\n",
       "    (block_4_7): ResNet_D_Bottleneck_Block(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU()\n",
       "    )\n",
       "    (block_4_8): ResNet_D_Bottleneck_Block(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU()\n",
       "    )\n",
       "    (block_5_1): ResNet_D_Bottleneck_Block(\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU()\n",
       "    )\n",
       "    (block_5_2): ResNet_D_Bottleneck_Block(\n",
       "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU()\n",
       "    )\n",
       "    (block_5_3): ResNet_D_Bottleneck_Block(\n",
       "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU()\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (linear): Linear(in_features=2048, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda:4\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Создаем DataFrame для записи метрик обучения в процессе обучения"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_name = ['epoch', 'time', 'current_lr', 'loss', 'accuracy_train', 'accuracy_val']\n",
    "metrics_file = open(save_metrics_dir + model_name + '.csv', 'w')\n",
    "metrics_file.writelines(', '.join(cols_name) + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'./metrics/ResNet56_Adam_lr0.01_b32_step_sc60.csv'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cols_name = ['epoch', 'time', 'current_lr', 'loss', 'accuracy_train', 'accuracy_val']\n",
    "metrics_frame = pd.DataFrame(columns=cols_name)\n",
    "metrics_frame_file = ('./metrics/' + model_name + '.csv')\n",
    "metrics_frame_file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Тренировочный цикл"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Основная метрика accuracy (топ1).<br>\n",
    "- В цикле используется упрощенный подсчет accuracy в конце каждой эпохи для ускорения обучения.<br>\n",
    "Если в конце эпохи ускоренный подсчет показывает интересный результат, то метрика на тестовом датасете будет посчитана честно.\n",
    "- Сохранение модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/365, Time: 73.54 sec, current_lr: 2.00e-03, Loss: 1.948, Accuracy_train: 0.206, Accuracy_val: 0.266\n",
      "Epoch 2/365, Time: 72.96 sec, current_lr: 3.99e-03, Loss: 1.998, Accuracy_train: 0.283, Accuracy_val: 0.282\n",
      "Epoch 3/365, Time: 72.95 sec, current_lr: 5.98e-03, Loss: 1.906, Accuracy_train: 0.320, Accuracy_val: 0.290\n",
      "Epoch 4/365, Time: 72.22 sec, current_lr: 7.97e-03, Loss: 1.984, Accuracy_train: 0.325, Accuracy_val: 0.324\n",
      "Epoch 5/365, Time: 73.14 sec, current_lr: 9.97e-03, Loss: 2.406, Accuracy_train: 0.313, Accuracy_val: 0.270\n",
      "Epoch 6/365, Time: 72.46 sec, current_lr: 9.97e-03, Loss: 1.795, Accuracy_train: 0.433, Accuracy_val: 0.466\n",
      "Epoch 7/365, Time: 73.40 sec, current_lr: 9.97e-03, Loss: 1.989, Accuracy_train: 0.399, Accuracy_val: 0.407\n",
      "Epoch 8/365, Time: 72.40 sec, current_lr: 9.97e-03, Loss: 1.926, Accuracy_train: 0.545, Accuracy_val: 0.522\n",
      "Epoch 9/365, Time: 72.80 sec, current_lr: 9.97e-03, Loss: 1.434, Accuracy_train: 0.558, Accuracy_val: 0.552\n",
      "Epoch 10/365, Time: 72.51 sec, current_lr: 9.97e-03, Loss: 1.646, Accuracy_train: 0.543, Accuracy_val: 0.582\n",
      "Epoch 11/365, Time: 72.64 sec, current_lr: 9.97e-03, Loss: 1.754, Accuracy_train: 0.557, Accuracy_val: 0.576\n",
      "Epoch 12/365, Time: 72.32 sec, current_lr: 9.97e-03, Loss: 1.566, Accuracy_train: 0.631, Accuracy_val: 0.630\n",
      "Epoch 13/365, Time: 71.87 sec, current_lr: 9.97e-03, Loss: 1.230, Accuracy_train: 0.609, Accuracy_val: 0.645\n",
      "Epoch 14/365, Time: 73.18 sec, current_lr: 9.97e-03, Loss: 0.938, Accuracy_train: 0.587, Accuracy_val: 0.584\n",
      "Epoch 15/365, Time: 71.82 sec, current_lr: 9.97e-03, Loss: 1.713, Accuracy_train: 0.597, Accuracy_val: 0.594\n",
      "Epoch 16/365, Time: 72.11 sec, current_lr: 9.97e-03, Loss: 1.556, Accuracy_train: 0.553, Accuracy_val: 0.560\n",
      "Epoch 17/365, Time: 72.24 sec, current_lr: 9.97e-03, Loss: 1.228, Accuracy_train: 0.606, Accuracy_val: 0.626\n",
      "Epoch 18/365, Time: 72.85 sec, current_lr: 9.97e-03, Loss: 1.245, Accuracy_train: 0.638, Accuracy_val: 0.689\n",
      "Epoch 19/365, Time: 72.60 sec, current_lr: 9.97e-03, Loss: 1.818, Accuracy_train: 0.660, Accuracy_val: 0.645\n",
      "Epoch 20/365, Time: 73.18 sec, current_lr: 9.97e-03, Loss: 1.469, Accuracy_train: 0.619, Accuracy_val: 0.688\n",
      "Epoch 21/365, Time: 71.90 sec, current_lr: 9.97e-03, Loss: 1.382, Accuracy_train: 0.645, Accuracy_val: 0.631\n",
      "Epoch 22/365, Time: 72.33 sec, current_lr: 9.97e-03, Loss: 2.368, Accuracy_train: 0.685, Accuracy_val: 0.713\n",
      "Epoch 23/365, Time: 73.28 sec, current_lr: 9.97e-03, Loss: 1.345, Accuracy_train: 0.621, Accuracy_val: 0.615\n",
      "Epoch 24/365, Time: 73.29 sec, current_lr: 9.97e-03, Loss: 1.316, Accuracy_train: 0.636, Accuracy_val: 0.657\n",
      "Epoch 25/365, Time: 73.48 sec, current_lr: 9.97e-03, Loss: 1.449, Accuracy_train: 0.574, Accuracy_val: 0.612\n",
      "Epoch 26/365, Time: 72.62 sec, current_lr: 9.97e-03, Loss: 1.423, Accuracy_train: 0.660, Accuracy_val: 0.656\n",
      "Epoch 27/365, Time: 72.86 sec, current_lr: 9.97e-03, Loss: 0.939, Accuracy_train: 0.665, Accuracy_val: 0.694\n",
      "Epoch 28/365, Time: 72.55 sec, current_lr: 9.97e-03, Loss: 1.502, Accuracy_train: 0.675, Accuracy_val: 0.717\n",
      "Epoch 29/365, Time: 72.00 sec, current_lr: 9.97e-03, Loss: 1.350, Accuracy_train: 0.679, Accuracy_val: 0.684\n",
      "Epoch 30/365, Time: 72.33 sec, current_lr: 9.97e-03, Loss: 0.972, Accuracy_train: 0.450, Accuracy_val: 0.493\n",
      "Epoch 31/365, Time: 72.68 sec, current_lr: 9.97e-03, Loss: 1.163, Accuracy_train: 0.692, Accuracy_val: 0.700\n",
      "Epoch 32/365, Time: 72.78 sec, current_lr: 9.97e-03, Loss: 1.840, Accuracy_train: 0.690, Accuracy_val: 0.691\n",
      "Epoch 33/365, Time: 71.81 sec, current_lr: 9.97e-03, Loss: 0.691, Accuracy_train: 0.631, Accuracy_val: 0.677\n",
      "Epoch 34/365, Time: 72.54 sec, current_lr: 9.97e-03, Loss: 1.143, Accuracy_train: 0.690, Accuracy_val: 0.712\n",
      "Epoch 35/365, Time: 74.04 sec, current_lr: 9.97e-03, Loss: 0.741, Accuracy_train: 0.701, Accuracy_val: 0.678\n",
      "Epoch 36/365, Time: 72.90 sec, current_lr: 9.97e-03, Loss: 1.812, Accuracy_train: 0.665, Accuracy_val: 0.717\n",
      "Epoch 37/365, Time: 71.68 sec, current_lr: 9.97e-03, Loss: 1.693, Accuracy_train: 0.699, Accuracy_val: 0.681\n",
      "Epoch 38/365, Time: 72.97 sec, current_lr: 9.97e-03, Loss: 1.131, Accuracy_train: 0.724, Accuracy_val: 0.740\n",
      "Epoch 39/365, Time: 73.39 sec, current_lr: 9.97e-03, Loss: 1.252, Accuracy_train: 0.675, Accuracy_val: 0.702\n",
      "Epoch 40/365, Time: 72.52 sec, current_lr: 9.97e-03, Loss: 1.148, Accuracy_train: 0.734, Accuracy_val: 0.719\n",
      "Epoch 41/365, Time: 72.01 sec, current_lr: 9.97e-03, Loss: 1.084, Accuracy_train: 0.690, Accuracy_val: 0.712\n",
      "Epoch 42/365, Time: 72.46 sec, current_lr: 9.97e-03, Loss: 1.054, Accuracy_train: 0.723, Accuracy_val: 0.739\n",
      "Epoch 43/365, Time: 72.13 sec, current_lr: 9.97e-03, Loss: 0.946, Accuracy_train: 0.679, Accuracy_val: 0.719\n",
      "Epoch 44/365, Time: 73.05 sec, current_lr: 9.97e-03, Loss: 1.164, Accuracy_train: 0.697, Accuracy_val: 0.722\n",
      "Epoch 45/365, Time: 72.82 sec, current_lr: 9.97e-03, Loss: 1.551, Accuracy_train: 0.629, Accuracy_val: 0.668\n",
      "Epoch 46/365, Time: 72.42 sec, current_lr: 9.97e-03, Loss: 2.031, Accuracy_train: 0.711, Accuracy_val: 0.732\n",
      "Epoch 47/365, Time: 73.58 sec, current_lr: 9.97e-03, Loss: 1.175, Accuracy_train: 0.731, Accuracy_val: 0.734\n",
      "Epoch 48/365, Time: 73.25 sec, current_lr: 9.97e-03, Loss: 1.115, Accuracy_train: 0.707, Accuracy_val: 0.750\n",
      "Epoch 49/365, Time: 72.02 sec, current_lr: 9.97e-03, Loss: 1.305, Accuracy_train: 0.714, Accuracy_val: 0.718\n",
      "Epoch 50/365, Time: 73.49 sec, current_lr: 9.97e-03, Loss: 1.526, Accuracy_train: 0.719, Accuracy_val: 0.734\n",
      "Epoch 51/365, Time: 72.44 sec, current_lr: 9.97e-03, Loss: 1.433, Accuracy_train: 0.687, Accuracy_val: 0.714\n",
      "Epoch 52/365, Time: 73.51 sec, current_lr: 9.97e-03, Loss: 0.972, Accuracy_train: 0.712, Accuracy_val: 0.746\n",
      "Epoch 53/365, Time: 73.25 sec, current_lr: 9.97e-03, Loss: 0.585, Accuracy_train: 0.736, Accuracy_val: 0.738\n",
      "Epoch 54/365, Time: 72.20 sec, current_lr: 9.97e-03, Loss: 1.213, Accuracy_train: 0.726, Accuracy_val: 0.750\n",
      "Epoch 55/365, Time: 72.93 sec, current_lr: 9.97e-03, Loss: 0.678, Accuracy_train: 0.736, Accuracy_val: 0.754\n",
      "Epoch 56/365, Time: 72.41 sec, current_lr: 9.97e-03, Loss: 1.396, Accuracy_train: 0.655, Accuracy_val: 0.728\n",
      "Epoch 57/365, Time: 72.54 sec, current_lr: 9.97e-03, Loss: 1.088, Accuracy_train: 0.753, Accuracy_val: 0.732\n",
      "Epoch 58/365, Time: 71.57 sec, current_lr: 9.97e-03, Loss: 1.053, Accuracy_train: 0.675, Accuracy_val: 0.689\n",
      "Epoch 59/365, Time: 72.64 sec, current_lr: 9.97e-03, Loss: 1.133, Accuracy_train: 0.721, Accuracy_val: 0.750\n",
      "Epoch 60/365, Time: 72.72 sec, current_lr: 9.97e-03, Loss: 1.258, Accuracy_train: 0.660, Accuracy_val: 0.682\n",
      "Epoch 61/365, Time: 72.89 sec, current_lr: 9.97e-03, Loss: 1.141, Accuracy_train: 0.702, Accuracy_val: 0.719\n",
      "Epoch 62/365, Time: 72.02 sec, current_lr: 9.97e-03, Loss: 0.981, Accuracy_train: 0.719, Accuracy_val: 0.734\n",
      "Epoch 63/365, Time: 72.36 sec, current_lr: 9.97e-03, Loss: 0.700, Accuracy_train: 0.736, Accuracy_val: 0.733\n",
      "Epoch 64/365, Time: 73.58 sec, current_lr: 9.97e-03, Loss: 0.823, Accuracy_train: 0.631, Accuracy_val: 0.696\n",
      "Epoch 65/365, Time: 72.91 sec, current_lr: 9.97e-04, Loss: 0.867, Accuracy_train: 0.689, Accuracy_val: 0.716\n",
      "Epoch 66/365, Time: 88.53 sec, current_lr: 9.97e-04, Loss: 1.084, Accuracy_train: 0.805, Accuracy_val: 0.822\n",
      "Epoch 67/365, Time: 90.75 sec, current_lr: 9.97e-04, Loss: 1.491, Accuracy_train: 0.821, Accuracy_val: 0.809\n",
      "Epoch 68/365, Time: 90.78 sec, current_lr: 9.97e-04, Loss: 1.019, Accuracy_train: 0.780, Accuracy_val: 0.812\n",
      "Epoch 69/365, Time: 90.37 sec, current_lr: 9.97e-04, Loss: 1.172, Accuracy_train: 0.787, Accuracy_val: 0.796\n",
      "Epoch 70/365, Time: 89.55 sec, current_lr: 9.97e-04, Loss: 1.075, Accuracy_train: 0.790, Accuracy_val: 0.796\n",
      "Epoch 71/365, Time: 90.97 sec, current_lr: 9.97e-04, Loss: 1.330, Accuracy_train: 0.816, Accuracy_val: 0.778\n",
      "Epoch 72/365, Time: 72.33 sec, current_lr: 9.97e-04, Loss: 0.968, Accuracy_train: 0.778, Accuracy_val: 0.809\n",
      "Epoch 73/365, Time: 84.96 sec, current_lr: 9.97e-04, Loss: 1.141, Accuracy_train: 0.810, Accuracy_val: 0.815\n",
      "Epoch 74/365, Time: 77.57 sec, current_lr: 9.97e-04, Loss: 0.977, Accuracy_train: 0.812, Accuracy_val: 0.804\n",
      "Epoch 75/365, Time: 90.77 sec, current_lr: 9.97e-04, Loss: 1.379, Accuracy_train: 0.807, Accuracy_val: 0.795\n",
      "Epoch 76/365, Time: 91.02 sec, current_lr: 9.97e-04, Loss: 0.886, Accuracy_train: 0.810, Accuracy_val: 0.824\n",
      "Epoch 77/365, Time: 91.27 sec, current_lr: 9.97e-04, Loss: 1.880, Accuracy_train: 0.827, Accuracy_val: 0.799\n",
      "Epoch 78/365, Time: 90.35 sec, current_lr: 9.97e-04, Loss: 1.162, Accuracy_train: 0.846, Accuracy_val: 0.810\n",
      "Epoch 79/365, Time: 91.01 sec, current_lr: 9.97e-04, Loss: 0.975, Accuracy_train: 0.790, Accuracy_val: 0.801\n",
      "Epoch 80/365, Time: 90.65 sec, current_lr: 9.97e-04, Loss: 1.278, Accuracy_train: 0.817, Accuracy_val: 0.807\n",
      "Epoch 81/365, Time: 89.79 sec, current_lr: 9.97e-04, Loss: 1.493, Accuracy_train: 0.814, Accuracy_val: 0.810\n",
      "Epoch 82/365, Time: 90.83 sec, current_lr: 9.97e-04, Loss: 0.859, Accuracy_train: 0.814, Accuracy_val: 0.815\n",
      "Epoch 83/365, Time: 89.93 sec, current_lr: 9.97e-04, Loss: 1.027, Accuracy_train: 0.826, Accuracy_val: 0.812\n",
      "Epoch 84/365, Time: 90.42 sec, current_lr: 9.97e-04, Loss: 0.932, Accuracy_train: 0.824, Accuracy_val: 0.833\n",
      "Epoch 85/365, Time: 91.43 sec, current_lr: 9.97e-04, Loss: 0.951, Accuracy_train: 0.824, Accuracy_val: 0.805\n",
      "Epoch 86/365, Time: 90.50 sec, current_lr: 9.97e-04, Loss: 1.247, Accuracy_train: 0.829, Accuracy_val: 0.826\n",
      "Epoch 87/365, Time: 90.84 sec, current_lr: 9.97e-04, Loss: 0.589, Accuracy_train: 0.814, Accuracy_val: 0.827\n",
      "Epoch 88/365, Time: 89.59 sec, current_lr: 9.97e-04, Loss: 0.940, Accuracy_train: 0.832, Accuracy_val: 0.803\n",
      "Epoch 89/365, Time: 90.77 sec, current_lr: 9.97e-04, Loss: 1.274, Accuracy_train: 0.814, Accuracy_val: 0.823\n",
      "Epoch 90/365, Time: 89.78 sec, current_lr: 9.97e-04, Loss: 0.900, Accuracy_train: 0.844, Accuracy_val: 0.809\n",
      "Epoch 91/365, Time: 89.29 sec, current_lr: 9.97e-04, Loss: 0.844, Accuracy_train: 0.836, Accuracy_val: 0.822\n",
      "Epoch 92/365, Time: 86.34 sec, current_lr: 9.97e-04, Loss: 1.049, Accuracy_train: 0.817, Accuracy_val: 0.832\n",
      "Epoch 93/365, Time: 85.71 sec, current_lr: 9.97e-04, Loss: 1.148, Accuracy_train: 0.856, Accuracy_val: 0.831\n",
      "Epoch 94/365, Time: 90.68 sec, current_lr: 9.97e-04, Loss: 1.280, Accuracy_train: 0.816, Accuracy_val: 0.800\n",
      "Epoch 95/365, Time: 90.17 sec, current_lr: 9.97e-04, Loss: 0.747, Accuracy_train: 0.827, Accuracy_val: 0.823\n",
      "Epoch 96/365, Time: 92.13 sec, current_lr: 9.97e-04, Loss: 0.714, Accuracy_train: 0.834, Accuracy_val: 0.822\n",
      "Epoch 97/365, Time: 90.23 sec, current_lr: 9.97e-04, Loss: 1.151, Accuracy_train: 0.822, Accuracy_val: 0.823\n",
      "Epoch 98/365, Time: 90.29 sec, current_lr: 9.97e-04, Loss: 0.970, Accuracy_train: 0.829, Accuracy_val: 0.794\n",
      "Epoch 99/365, Time: 89.47 sec, current_lr: 9.97e-04, Loss: 0.791, Accuracy_train: 0.853, Accuracy_val: 0.809\n",
      "Epoch 100/365, Time: 91.96 sec, current_lr: 9.97e-04, Loss: 0.689, Accuracy_train: 0.834, Accuracy_val: 0.832\n",
      "Epoch 101/365, Time: 89.67 sec, current_lr: 9.97e-04, Loss: 1.071, Accuracy_train: 0.812, Accuracy_val: 0.844\n",
      "Epoch 102/365, Time: 90.96 sec, current_lr: 9.97e-04, Loss: 1.742, Accuracy_train: 0.817, Accuracy_val: 0.803\n",
      "Epoch 103/365, Time: 89.48 sec, current_lr: 9.97e-04, Loss: 0.590, Accuracy_train: 0.824, Accuracy_val: 0.796\n",
      "Epoch 104/365, Time: 90.84 sec, current_lr: 9.97e-04, Loss: 1.023, Accuracy_train: 0.810, Accuracy_val: 0.838\n",
      "Epoch 105/365, Time: 90.70 sec, current_lr: 9.97e-04, Loss: 1.752, Accuracy_train: 0.829, Accuracy_val: 0.817\n",
      "Epoch 106/365, Time: 90.85 sec, current_lr: 9.97e-04, Loss: 1.201, Accuracy_train: 0.839, Accuracy_val: 0.812\n",
      "Epoch 107/365, Time: 91.84 sec, current_lr: 9.97e-04, Loss: 0.975, Accuracy_train: 0.839, Accuracy_val: 0.820\n",
      "Epoch 108/365, Time: 90.15 sec, current_lr: 9.97e-04, Loss: 0.873, Accuracy_train: 0.838, Accuracy_val: 0.837\n",
      "Epoch 109/365, Time: 90.26 sec, current_lr: 9.97e-04, Loss: 1.172, Accuracy_train: 0.831, Accuracy_val: 0.824\n",
      "Epoch 110/365, Time: 91.99 sec, current_lr: 9.97e-04, Loss: 0.794, Accuracy_train: 0.851, Accuracy_val: 0.821\n",
      "Epoch 111/365, Time: 91.73 sec, current_lr: 9.97e-04, Loss: 0.924, Accuracy_train: 0.821, Accuracy_val: 0.834\n",
      "Epoch 112/365, Time: 90.08 sec, current_lr: 9.97e-04, Loss: 0.675, Accuracy_train: 0.832, Accuracy_val: 0.823\n",
      "Epoch 113/365, Time: 91.15 sec, current_lr: 9.97e-04, Loss: 0.774, Accuracy_train: 0.824, Accuracy_val: 0.818\n",
      "Epoch 114/365, Time: 90.91 sec, current_lr: 9.97e-04, Loss: 1.049, Accuracy_train: 0.846, Accuracy_val: 0.806\n",
      "Epoch 115/365, Time: 91.31 sec, current_lr: 9.97e-04, Loss: 1.062, Accuracy_train: 0.834, Accuracy_val: 0.808\n",
      "Epoch 116/365, Time: 92.15 sec, current_lr: 9.97e-04, Loss: 1.022, Accuracy_train: 0.866, Accuracy_val: 0.820\n",
      "Epoch 117/365, Time: 91.99 sec, current_lr: 9.97e-04, Loss: 1.063, Accuracy_train: 0.861, Accuracy_val: 0.830\n",
      "Epoch 118/365, Time: 89.67 sec, current_lr: 9.97e-04, Loss: 1.540, Accuracy_train: 0.854, Accuracy_val: 0.849\n",
      "Epoch 119/365, Time: 89.74 sec, current_lr: 9.97e-04, Loss: 1.114, Accuracy_train: 0.832, Accuracy_val: 0.830\n",
      "Epoch 120/365, Time: 89.37 sec, current_lr: 9.97e-04, Loss: 1.700, Accuracy_train: 0.829, Accuracy_val: 0.834\n",
      "Epoch 121/365, Time: 90.86 sec, current_lr: 9.97e-04, Loss: 0.881, Accuracy_train: 0.843, Accuracy_val: 0.835\n",
      "Epoch 122/365, Time: 91.93 sec, current_lr: 9.97e-04, Loss: 0.556, Accuracy_train: 0.865, Accuracy_val: 0.826\n"
     ]
    }
   ],
   "source": [
    "accuracy_max = 0\n",
    "for epoch in range(num_epoch):  # loop over the dataset multiple times\n",
    "\n",
    "    model.train()\n",
    "    start_time = time.time()\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "       \n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "#         inputs, labels = data\n",
    "#         print(data[1])\n",
    "        inputs, labels = data[0].to(device), data[1].to(device)\n",
    "#         print(labels)\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "       \n",
    "        # forward + backward + optimize\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "#         print('Loss: ', loss)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if epoch < 5:\n",
    "            scheduler_warmup.step()\n",
    "    if epoch >= 5:\n",
    "        scheduler.step()\n",
    "    \n",
    "    #Accuracy train and val\n",
    "    model.eval()\n",
    "    correct_train, correct_val = 0, 0\n",
    "    total_train, total_val = 0, 0\n",
    "    with torch.no_grad():\n",
    "        trainset_subset = torch.utils.data.Subset(trainset, np.random.randint(0,high=train_img_qty, size=train_img_qty//16))\n",
    "        trainset_dataloader = torch.utils.data.DataLoader(trainset_subset, batch_size=batch_size,\n",
    "                                                            shuffle=False)\n",
    "        for images, labels in trainset_dataloader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            outputs = outputs.to(device)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total_train += labels.size(0)\n",
    "            correct_train += (predicted == labels).sum().item()\n",
    "            \n",
    "        testset_subset = torch.utils.data.Subset(testset, np.random.randint(0,high=val_img_qty, size=val_img_qty//4))\n",
    "        testset_dataloader = torch.utils.data.DataLoader(testset_subset, batch_size=batch_size,\n",
    "                                                            shuffle=False)\n",
    "        for images, labels in testset_dataloader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            outputs = outputs.to(device)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total_val += labels.size(0)\n",
    "            correct_val += (predicted == labels).sum().item()\n",
    "            \n",
    "        if correct_val/total_val >= .88 and correct_val/total_val >= accuracy_max:\n",
    "            correct_val = 0\n",
    "            total_val = 0\n",
    "            with torch.no_grad():\n",
    "                for images, labels in testloader:\n",
    "                    images, labels = images.to(device), labels.to(device)\n",
    "                    outputs = model(images)\n",
    "                    outputs = outputs.to(device)\n",
    "                    _, predicted = torch.max(outputs.data, 1)\n",
    "                    total_val += labels.size(0)\n",
    "                    correct_val += (predicted == labels).sum().item()\n",
    "            accuracy_max = correct_val/total_val\n",
    "                    \n",
    "    end_time = time.time()\n",
    "    metrics = {'epoch': epoch+1,\n",
    "               'time': end_time - start_time,\n",
    "               'current_lr': [group['lr'] for group in optimizer.param_groups][0],\n",
    "               'loss': float(loss),\n",
    "               'accuracy_train': correct_train/total_train,\n",
    "               'accuracy_val': correct_val/total_val,\n",
    "               }\n",
    "\n",
    "    print(\"Epoch {}/{}, Time: {:.2f} sec, current_lr: {:.2e}, Loss: {:.3f}, Accuracy_train: {:.3f}, Accuracy_val: {:.3f}\".\n",
    "          format(metrics['epoch'], num_epoch, metrics['time'], metrics['current_lr'], metrics['loss'], metrics['accuracy_train'], metrics['accuracy_val']))\n",
    "    \n",
    "    metrics_frame = metrics_frame.append(pd.DataFrame.from_dict(metrics,orient='index').T)\n",
    "    metrics_frame.to_csv(metrics_frame_file,index=False)\n",
    "#     metrics = [epoch+1,\n",
    "#                end_time - start_time,\n",
    "#                [group['lr'] for group in optimizer.param_groups][0],\n",
    "#                float(loss),\n",
    "#                correct_train/total_train,\n",
    "#                correct_val/total_val,\n",
    "#               ]\n",
    "\n",
    "#     print(\"Epoch {}/{}, Time: {:.2f} sec, current_lr: {:.2e}, Loss: {:.3f}, Accuracy_train: {:.3f}, Accuracy_val: {:.3f}\".\n",
    "#           format(metrics[0], num_epoch, metrics[1], metrics[2], metrics[3], metrics[4], metrics[5]))\n",
    "    \n",
    "#     metrics_file.writelines(', '.join([str(m) for m in metrics]) + '\\n')\n",
    "    \n",
    "#     if save_best_model == True:\n",
    "#         if metrics['accuracy_val'] == metrics_frame['accuracy_val'].max():\n",
    "#             torch.save(model, save_model_dir + model_name + '.pt')\n",
    "            \n",
    "# if save_best_model == False:\n",
    "#     torch.save(model, save_model_dir + model_name + '.pt')\n",
    "# metrics_file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Проверка_модели"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Проверяем сохраненную модель на соответствие метрикам в процессе обучения."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.load(save_model_dir + model_name + '.pt')\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct_train, correct_val = 0, 0\n",
    "total_train, total_val = 0, 0\n",
    "with torch.no_grad():\n",
    "    for images, labels in testloader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        outputs = model(images)\n",
    "        outputs = outputs.to(device)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total_val += labels.size(0)\n",
    "        correct_val += (predicted == labels).sum().item()\n",
    "        \n",
    "# print('Accuracy final model on validation dataset is: {:.3f})'.format(correct_val/total_val))\n",
    "print(f'Accuracy final model on the validation dataset is: {(correct_val/total_val):.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Критика"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Известные проблемы:\n",
    "- агументации сильно увеличивают время обучения (+50%)\n",
    "- прирост accuracy от использования трюков отмечен только для cosine learning decay (sheduler_type = 'cos')\n",
    "- результат очень сильно зависит от стартового learning_rate. learning_rate для используемых оптимизаторов нужно выбирать в разном диапазоне (0,01-0,1 для SGD и 0,0005-0,03 для Adam), что приводит к некоторой путаницы\n",
    "- папки './model' и './metrics' должны быть созданы самостоятельно"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
