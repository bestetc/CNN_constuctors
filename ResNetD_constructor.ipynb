{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pipeline ResNet-D\n",
    "### В пайплайне используется контруктор ResNetD сетей взятой из [статьи](https://arxiv.org/pdf/1812.01187.pdf)\n",
    "- Accuracy на тестовом датасете состоавляет 0.92"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from torch import nn\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyper params\n",
    "batch_size = 64\n",
    "num_epoch = 10\n",
    "learning_rate = 0.025 # 0.1 * batch_size / 256\n",
    "sheduler_type = 'step' # 'cosine' or 'step'\n",
    "sheduler_cycle = 2\n",
    "warmup_epoch = 5\n",
    "optimizer_type = 'SGD' # 'SGD' or 'Adam'\n",
    "resnet_layers = [3,4,6,3]\n",
    "bottleneck = False\n",
    "num_classes = 10\n",
    "label_smoothing = 0.05\n",
    "save_best_model = True\n",
    "save_model_dir = './models/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if bottleneck == True:\n",
    "    model_name = f'ResNet{sum(resnet_layers)*3+2}_{optimizer_type}_lr{learning_rate}_b{batch_size}_{sheduler_type}_sc{(num_epoch-warmup_epoch)//sheduler_cycle}'\n",
    "elif bottleneck == False:\n",
    "    model_name = f'ResNet{sum(resnet_layers)*2+2}_{optimizer_type}_lr{learning_rate}_b{batch_size}_{sheduler_type}_sc{(num_epoch-warmup_epoch)//sheduler_cycle}'\n",
    "model_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_df = pd.read_csv('../imagenette/imagenette2-320/noisy_imagenette.csv')\n",
    "train_img_qty = len(labels_df[labels_df['is_valid'] == False])\n",
    "val_img_qty = len(labels_df[labels_df['is_valid'] == True])\n",
    "train_img_qty, val_img_qty"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Создаем DataLoader попутно предобрабатывая данные\n",
    "- Загрузку датасета можно найти в [ResNet_constructor.ipynb](./ResNet_constructor.ipynb)\n",
    "- Предварительный просмотр данных можно найти в [ResNet_constructor.ipynb](./ResNet_constructor.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import transforms, datasets\n",
    "\n",
    "train_transform = transforms.Compose([\n",
    "        transforms.Resize((260,260)),\n",
    "        transforms.RandomSizedCrop(224),\n",
    "#         transforms.ColorJitter(brightness=0.4, contrast=0.4, saturation=0.4, hue=0.2),\n",
    "#         transforms.RandomResizedCrop(224, scale=(0.08, 1.0), ratio=(0.75, 1.3333333333333333)),\n",
    "        transforms.RandomHorizontalFlip(.5),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                             std=[0.229, 0.224, 0.225])\n",
    "    ])\n",
    "test_transform = transforms.Compose([\n",
    "        transforms.Resize((224,224)),\n",
    "#         transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                             std=[0.229, 0.224, 0.225])\n",
    "    ])\n",
    "\n",
    "trainset = datasets.ImageFolder(root='../imagenette/imagenette2-320/train/', transform=train_transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size,\n",
    "                                          shuffle=True)\n",
    "testset = datasets.ImageFolder(root='../imagenette/imagenette2-320/val/', transform=test_transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, #batch_size=batch_size,\n",
    "                                         shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_per_epoch = len(trainloader)\n",
    "batch_per_epoch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Создаем конструктор ResNet-like сетей.\n",
    "\n",
    "### Конструктор представляет собой класс, который ожидает на вход следующие параметры:\n",
    "\n",
    " - layers - список с количеством стандартных блоков по слоям\n",
    " - num_classes - количество классов\n",
    " - bottleneck - определяет использование стандартных блоков или 'bottleneck' блоков \n",
    "\n",
    "(!) Конструктор ожидает на вход изображение с разрешением 224х224х3\n",
    "\n",
    "Примеры стандартных сетей:\n",
    "ResNet-18: \n",
    "model = ResNet_like(layers=[2,2,2,2], num_classes=10, bottleneck=False)\n",
    "\n",
    "ResNet-36: \n",
    "model = ResNet_like(layers=[3,4,6,3], num_classes=10, bottleneck=False)\n",
    "\n",
    "ResNet-50:\n",
    "model = ResNet_like(layers=[3,4,6,3], num_classes=10, bottleneck=True)\n",
    "\n",
    "ResNet-101:\n",
    "model = ResNet_like(layers=[3,4,23,3], num_classes=10, bottleneck=True)\n",
    "\n",
    "ResNet-152:\n",
    "model = ResNet_like(layers=[3,8,36,3], num_classes=10, bottleneck=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Выносим в функции сверточные слои для уменьшения количества букв в коде"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv1x1(in_channels, out_channels, stride=1):\n",
    "    return nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=stride, padding=0)\n",
    "\n",
    "def conv3x3(in_channels, out_channels, stride=1,padding=1):\n",
    "    return nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=stride, padding=padding)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Задаем базовые блоки через классы.\n",
    "Класс NormalBlock собирает стандартный ResNet блок с skipconnection'ом\n",
    "Класс BottleneckBlock собирает Bottleneck ResNet блок с skipconnection'ом\n",
    "\n",
    "Каждый класс ожидает параметры:\n",
    " - num_layer - порядковый номер слоя, в котором будет использоваться данных блок. В стандартной ResNet архитектуре блоки используются со второго слоя.\n",
    " - downsample - определяет тип downsampling'а.\n",
    "     - 0 - downsampling не используется\n",
    "     - 1 - downsampling используется в блоке, где уменьшается разрешение и увеличивается кол-во каналов\n",
    "     - -1 - downsampling используется в блоке, где разрешение не уменьшается, но увеличивается кол-во каналов (обычно последний слой)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NormalBlock(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        num_layer,\n",
    "        downsample = 0,\n",
    "        \n",
    "    ):\n",
    "        super(NormalBlock, self).__init__()\n",
    "        self.use_downsample = downsample\n",
    "        if num_layer == 2 and downsample == 1:\n",
    "            self.in_channels = 16*(2**num_layer)\n",
    "        elif num_layer > 2 and downsample != 0:\n",
    "            self.in_channels = 16*(2**(num_layer-1))\n",
    "        elif downsample == 0: \n",
    "            self.in_channels = 16*(2**num_layer)\n",
    "            \n",
    "        self.out_channels = 16*(2**num_layer)\n",
    "        \n",
    "        if downsample == 1:\n",
    "            self.downsample = nn.Sequential(\n",
    "                nn.AvgPool2d(kernel_size=2,stride=2),\n",
    "                conv1x1(self.in_channels, self.out_channels, stride=1),\n",
    "                nn.BatchNorm2d(self.out_channels))\n",
    "\n",
    "            self.conv1 = conv3x3(self.in_channels, self.out_channels,stride=2)\n",
    "        elif downsample == -1:\n",
    "            self.downsample = conv1x1(self.in_channels, self.out_channels, stride=1)\n",
    "            \n",
    "            self.conv1 = conv3x3(self.in_channels, self.out_channels, stride=1)\n",
    "            \n",
    "        elif downsample == 0:\n",
    "            self.conv1 = conv3x3(self.in_channels, self.out_channels, stride=1)\n",
    "        self.in_channels = self.out_channels\n",
    "        self.bn1 = nn.BatchNorm2d(self.out_channels)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.conv2 = conv3x3(self.in_channels, self.out_channels)\n",
    "        self.bn2 = nn.BatchNorm2d(self.out_channels)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        skip = x\n",
    "#         print('Block input',x.shape)\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "#         print('Block before skip',out.shape)\n",
    "\n",
    "        if self.use_downsample != 0:\n",
    "#             print('Before downsample',out.shape, skip.shape)\n",
    "#             if self.use_downsample == 1:\n",
    "#                 out = self.maxpool(out)\n",
    "            skip = self.downsample(x)\n",
    "#             print('After downsample',out.shape, skip.shape)\n",
    "        out += skip\n",
    "        out = self.relu(out)\n",
    "\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BottleneckBlock(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        num_layer,\n",
    "        downsample = 0\n",
    "        \n",
    "    ):\n",
    "        super(BottleneckBlock, self).__init__()\n",
    "        \n",
    "        self.use_downsample = downsample\n",
    "        if num_layer == 2 and downsample == 1:\n",
    "            self.in_channels = 16*(2**num_layer)\n",
    "        elif num_layer > 2 and downsample != 0:\n",
    "            self.in_channels = 16*(2**(num_layer-1))*4\n",
    "        elif downsample == 0: \n",
    "            self.in_channels = 16*(2**num_layer)*4\n",
    "            \n",
    "        self.out_channels = 16*(2**num_layer)\n",
    "   \n",
    "        if downsample == 1:\n",
    "            self.downsample = nn.Sequential(\n",
    "                nn.AvgPool2d(kernel_size=2,stride=2),\n",
    "                conv1x1(self.in_channels, self.out_channels*4, stride=1),\n",
    "                nn.BatchNorm2d(self.out_channels*4))\n",
    "\n",
    "            self.conv1 = conv1x1(self.in_channels, self.out_channels)\n",
    "            self.in_channels = self.out_channels\n",
    "            self.bn1 = nn.BatchNorm2d(self.out_channels)\n",
    "            self.conv2 = conv3x3(self.in_channels, self.out_channels,stride=2)\n",
    "        elif downsample == -1:\n",
    "            self.downsample = nn.Sequential(\n",
    "#                 nn.AvgPool2d(kernel_size=2,stride=2)\n",
    "                conv1x1(self.in_channels, self.out_channels*4, stride=1),\n",
    "                nn.BatchNorm2d(self.out_channels*4))\n",
    "            \n",
    "            self.conv1 = conv1x1(self.in_channels, self.out_channels)\n",
    "            self.in_channels = self.out_channels\n",
    "            self.bn1 = nn.BatchNorm2d(self.out_channels)\n",
    "            self.conv2 = conv3x3(self.in_channels, self.out_channels)\n",
    "\n",
    "        elif downsample == 0:\n",
    "            self.conv1 = conv1x1(self.in_channels, self.out_channels)\n",
    "            self.in_channels = self.out_channels\n",
    "            self.bn1 = nn.BatchNorm2d(self.out_channels)\n",
    "            self.conv2 = conv3x3(self.in_channels, self.out_channels)\n",
    "            \n",
    "        self.bn2 = nn.BatchNorm2d(self.out_channels)\n",
    "        self.out_channels = 16*(2**num_layer)*4\n",
    "        self.conv3 = conv1x1(self.in_channels, self.out_channels)\n",
    "        self.bn3 = nn.BatchNorm2d(self.out_channels)\n",
    "        self.in_channels = self.out_channels\n",
    "        self.relu = nn.ReLU()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        skip = x\n",
    "        \n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.conv3(out)\n",
    "        out = self.bn3(out)\n",
    "\n",
    "        if self.use_downsample != 0:\n",
    "#             print(out.shape, x.shape)\n",
    "#             if self.use_downsample == 1:\n",
    "#                 out = self.maxpool(out)\n",
    "            skip = self.downsample(x)\n",
    "#             print(out.shape, x.shape)\n",
    "        out += skip\n",
    "        out = self.relu(out)\n",
    "            \n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Класс конструктор ResNet подобных архитектур"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResNet_like(nn.Module):\n",
    "\n",
    "    def __init__(self, \n",
    "                 layers, \n",
    "                 num_classes,\n",
    "                 bottleneck,\n",
    "                 \n",
    "                 ):\n",
    "        \n",
    "        super(ResNet_like, self).__init__()\n",
    "        self.first = nn.Sequential(\n",
    "            conv3x3(3, 32, stride=2),\n",
    "            conv3x3(32, 32, stride=2),\n",
    "            conv3x3(32, 64))\n",
    "        \n",
    "        self.body = nn.Sequential()\n",
    "        if bottleneck == True:\n",
    "            for num, layer in enumerate(layers):\n",
    "                for block in range(layer):\n",
    "                    if block == 0  and num < len(layers) - 1:\n",
    "                        downsample = 1\n",
    "                    elif block == 0 and num == len(layers) - 1:\n",
    "                        downsample = -1\n",
    "                    elif block != 0:  \n",
    "                        downsample = 0\n",
    "                    self.body.add_module(name='block_%d_%d'%(num+2,block+1), module=BottleneckBlock(num+2, downsample))\n",
    "        elif bottleneck == False:\n",
    "            for num, layer in enumerate(layers):\n",
    "                for block in range(layer):\n",
    "                    if block == 0  and num < len(layers) - 1:\n",
    "                        downsample = 1\n",
    "                    elif block == 0 and num == len(layers) - 1:\n",
    "                        downsample = -1\n",
    "                    elif block != 0:  \n",
    "                        downsample = 0\n",
    "                    self.body.add_module(name='block_%d_%d'%(num+2,block+1), module=NormalBlock(num+2, downsample))\n",
    "        \n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((1,1))\n",
    "        if bottleneck == True:\n",
    "            self.linear_input = 32*(2**(len(layers)))*4\n",
    "        else:\n",
    "            self.linear_input = 32*(2**(len(layers)))\n",
    "        self.linear = nn.Linear(self.linear_input, num_classes)\n",
    "        \n",
    "    def forward(self, x):\n",
    "\n",
    "        x = self.first(x)\n",
    "#         print('Shape input body:', x.shape)\n",
    "        x = self.body(x)\n",
    "#         print('Shape input avgpool:', x.shape)\n",
    "        x = self.avgpool(x)\n",
    "#         print('Shape input linear:', x.shape)\n",
    "        x = x.view(x.size(0), -1)\n",
    "#         print('Shape input linear:', x.shape)\n",
    "        x = self.linear(x)\n",
    "#         x = self.final(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn.modules.loss import _WeightedLoss\n",
    "\n",
    "class SmoothCrossEntropyLoss(_WeightedLoss):\n",
    "    def __init__(self, weight=None, reduction='mean', smoothing=0.0):\n",
    "        super().__init__(weight=weight, reduction=reduction)\n",
    "        self.smoothing = smoothing\n",
    "        self.weight = weight\n",
    "        self.reduction = reduction\n",
    "\n",
    "    def k_one_hot(self, targets:torch.Tensor, n_classes:int, smoothing=0.0):\n",
    "        with torch.no_grad():\n",
    "            targets = torch.empty(size=(targets.size(0), n_classes),\n",
    "                                  device=targets.device) \\\n",
    "                                  .fill_(smoothing /(n_classes-1)) \\\n",
    "                                  .scatter_(1, targets.data.unsqueeze(1), 1.-smoothing)\n",
    "        return targets\n",
    "\n",
    "    def reduce_loss(self, loss):\n",
    "        return loss.mean() if self.reduction == 'mean' else loss.sum() \\\n",
    "        if self.reduction == 'sum' else loss\n",
    "\n",
    "    def forward(self, inputs, targets):\n",
    "        assert 0 <= self.smoothing < 1\n",
    "\n",
    "        targets = self.k_one_hot(targets, inputs.size(-1), self.smoothing)\n",
    "        log_preds = torch.nn.functional.log_softmax(inputs, -1)\n",
    "\n",
    "        if self.weight is not None:\n",
    "            log_preds = log_preds * self.weight.unsqueeze(0)\n",
    "\n",
    "        return self.reduce_loss(-(targets * log_preds).sum(dim=-1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Инициализируем модель с через конструктор"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ResNet_like(layers=resnet_layers, num_classes=num_classes, bottleneck=bottleneck)\n",
    "criterion = SmoothCrossEntropyLoss(smoothing=label_smoothing) #nn.CrossEntropyLoss()\n",
    "if optimizer_type == 'SGD':\n",
    "    optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate, weight_decay=0.0001, momentum=0.9)\n",
    "elif optimizer_type == 'Adam':\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate, betas=(0.95, 0.99), eps=1e-06, weight_decay=0.0001, amsgrad=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if sheduler_type == 'step':\n",
    "    scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=(num_epoch-warmup_epoch)//sheduler_cycle, gamma=0.1)\n",
    "    if warmup_epoch > 0:\n",
    "        scheduler_warmup = torch.optim.lr_scheduler.CyclicLR(optimizer, \n",
    "                                                         base_lr=learning_rate/(batch_per_epoch*warmup_epoch), \n",
    "                                                         max_lr=learning_rate,\n",
    "                                                         step_size_up=((batch_per_epoch+1)*warmup_epoch), # should be batch_per_epoch + 1\n",
    "                                                         step_size_down=0,\n",
    "                                                         cycle_momentum=False,\n",
    "                                                        )    \n",
    "elif sheduler_type == 'cos':\n",
    "    scheduler = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, (num_epoch-warmup_epoch)//sheduler_cycle, eta_min=0)\n",
    "    if warmup_epoch > 0:\n",
    "        scheduler_warmup = torch.optim.lr_scheduler.CyclicLR(optimizer, \n",
    "                                                         base_lr=learning_rate/(batch_per_epoch*warmup_epoch), \n",
    "                                                         max_lr=learning_rate,\n",
    "                                                         step_size_up=((batch_per_epoch+1)*warmup_epoch), # should be batch_per_epoch + 1\n",
    "                                                         step_size_down=0,\n",
    "                                                         cycle_momentum=False,\n",
    "                                                        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ячейча используется для запуска реализации ResNet в библиотеке PyTorch для сравнения с конструктором."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from torchvision.models import resnet34\n",
    "# model = resnet34(num_classes=10)\n",
    "# criterion = nn.CrossEntropyLoss()\n",
    "# optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate, weight_decay=0.0001, momentum=0.9)\n",
    "# # optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate, betas=(0.95, 0.99), eps=1e-06, weight_decay=0.0001, amsgrad=False)\n",
    "# # scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=40, gamma=0.1)\n",
    "# scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, num_epoch, eta_min=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Загружаем модель на видеокарту."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:4\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_name = ['epoch', 'time', 'current_lr', 'loss', 'accuracy_train', 'accuracy_val']\n",
    "metrics_frame = pd.DataFrame(columns=cols_name)\n",
    "metrics_frame_file = ('./metrics/' + model_name + '.csv')\n",
    "metrics_frame_file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Основной тренировочный цикл и подсчет метрик.\n",
    "    Основная метрика accuracy (топ1). Очень не хотелось бы получать ошибку на топ5 accuracy при 10 классах."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(num_epoch):  # loop over the dataset multiple times\n",
    "\n",
    "    model.train()\n",
    "    start_time = time.time()\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "       \n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "#         inputs, labels = data\n",
    "#         print(data[1])\n",
    "        inputs, labels = data[0].to(device), data[1].to(device)\n",
    "#         print(labels)\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "       \n",
    "        # forward + backward + optimize\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "#         print('Loss: ', loss)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if epoch < 5:\n",
    "            scheduler_warmup.step()\n",
    "    if epoch >= 5:\n",
    "        scheduler.step()\n",
    "    \n",
    "    #Accuracy train and val\n",
    "    model.eval()\n",
    "    correct_train, correct_val = 0, 0\n",
    "    total_train, total_val = 0, 0\n",
    "    with torch.no_grad():\n",
    "        trainset_subset = torch.utils.data.Subset(trainset, np.random.randint(0,high=train_img_qty, size=train_img_qty//16))\n",
    "        trainset_dataloader = torch.utils.data.DataLoader(trainset_subset, batch_size=batch_size,\n",
    "                                                            shuffle=False)\n",
    "        for images, labels in trainset_dataloader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            outputs = outputs.to(device)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total_train += labels.size(0)\n",
    "            correct_train += (predicted == labels).sum().item()\n",
    "        testset_subset = torch.utils.data.Subset(testset, np.random.randint(0,high=val_img_qty, size=val_img_qty//4))\n",
    "        testset_dataloader = torch.utils.data.DataLoader(testset_subset, batch_size=batch_size,\n",
    "                                                            shuffle=False)\n",
    "        for images, labels in testset_dataloader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            outputs = outputs.to(device)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total_val += labels.size(0)\n",
    "            correct_val += (predicted == labels).sum().item()\n",
    "            \n",
    "        if correct_train/total_train >= .6 and correct_train/total_train >= metrics_frame['accuracy_val'].max():\n",
    "            correct_val = 0\n",
    "            total_val = 0\n",
    "            with torch.no_grad():\n",
    "                for images, labels in testloader:\n",
    "                    images, labels = images.to(device), labels.to(device)\n",
    "                    outputs = model(images)\n",
    "                    outputs = outputs.to(device)\n",
    "                    _, predicted = torch.max(outputs.data, 1)\n",
    "                    total_val += labels.size(0)\n",
    "                    correct_val += (predicted == labels).sum().item()\n",
    "                    \n",
    "    end_time = time.time()\n",
    "    metrics = {'epoch': epoch+1,\n",
    "               'time': end_time - start_time,\n",
    "               'current_lr': [group['lr'] for group in optimizer.param_groups][0],\n",
    "               'loss': float(loss),\n",
    "               'accuracy_train': correct_train/total_train,\n",
    "               'accuracy_val': correct_val/total_val,\n",
    "               }\n",
    "\n",
    "    print(\"Epoch {}/{}, Time: {:.2f} sec, current_lr: {:.2e}, Loss: {:.3f}, Accuracy_train: {:.3f}, Accuracy_val: {:.3f}\".\n",
    "          format(metrics['epoch'], num_epoch, metrics['time'], metrics['current_lr'], metrics['loss'], metrics['accuracy_train'], metrics['accuracy_val']))\n",
    "    \n",
    "    metrics_frame = metrics_frame.append(pd.DataFrame.from_dict(metrics,orient='index').T)\n",
    "    metrics_frame.to_csv(metrics_frame_file,index=False)\n",
    "    \n",
    "    if save_best_model == True:\n",
    "        if metrics['accuracy_val'] == metrics_frame['accuracy_val'].max():\n",
    "            torch.save(model, save_model_dir + model_name + '.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.load(save_model_dir + model_name + '.pt')\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct_train, correct_val = 0, 0\n",
    "total_train, total_val = 0, 0\n",
    "with torch.no_grad():\n",
    "    for images, labels in testloader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        outputs = model(images)\n",
    "        outputs = outputs.to(device)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total_val += labels.size(0)\n",
    "        correct_val += (predicted == labels).sum().item()\n",
    "        \n",
    "# print('Accuracy final model on validation dataset is: {:.3f})'.format(correct_val/total_val))\n",
    "print(f'Accuracy final model on the validation dataset is: {(correct_val/total_val):.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
