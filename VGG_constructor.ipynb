{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pipeline. На 120 эпохах accuracy на тестовом датасете 88.4%.\n",
    "### На 450 эпохах accuracy 90.3%\n",
    "Обучение проходит на датасете Imagenette.\n",
    "Информацию по загрузке датасета можно найти в VGG_like.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "from torch import nn\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from modules import datasets_loader, train_tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyper params\n",
    "batch_size = 32\n",
    "num_epoch = 120\n",
    "learning_rate = 0.0003\n",
    "optimizer_type = 'Adam'\n",
    "\n",
    "scheduler_type = 'cos'\n",
    "cosine_cycles = 2\n",
    "decay_steps = 5\n",
    "\n",
    "save_best_model = False\n",
    "save_model_dir = './models/'\n",
    "metrics_dir = './metrics/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Создаем DataLoader попутно предобрабатывая данные\n",
    "- Загрузку датасета можно найти в [ResNet-constructor](ResNet_constructor.ipynb)\n",
    "- Предварительный смотр данных можно найти в [ResNet-constructor](ResNet_constructor.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/torchvision/transforms/transforms.py:841: UserWarning: The use of the transforms.RandomSizedCrop transform is deprecated, please use transforms.RandomResizedCrop instead.\n",
      "  \"please use transforms.RandomResizedCrop instead.\")\n"
     ]
    }
   ],
   "source": [
    "from torchvision import transforms, datasets\n",
    "\n",
    "train_transform = transforms.Compose([\n",
    "        transforms.Resize((260,260)),\n",
    "        transforms.RandomSizedCrop(224),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                             std=[0.229, 0.224, 0.225])\n",
    "    ])\n",
    "test_transform = transforms.Compose([\n",
    "        transforms.Resize((224,224)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                             std=[0.229, 0.224, 0.225])\n",
    "    ])\n",
    "\n",
    "torch.set_num_threads(8)\n",
    "trainset = datasets.ImageFolder(root='../imagenette/imagenette2-320/train/', transform=train_transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size,\n",
    "                                          shuffle=True)\n",
    "testset = datasets.ImageFolder(root='../imagenette/imagenette2-320/val/', transform=test_transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, #batch_size=batch_size,\n",
    "                                         shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "296"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(trainloader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Создаем конструктор VGG-like сетей.\n",
    "\n",
    "### В конструктор подается словарь с параметрами сети:\n",
    "\n",
    " - body_input - разрешение и кол-во каналов входящего изображения [высота, ширина, каналы].\n",
    " - conv_layers - параметры сверточных блоков тела сети. Каждый блок задается как [кол-во сверточных слоев, padding, stride]. \n",
    " Padding и stride задаются для всех сверточных слоев в данном блоке.\n",
    " - linear_layers - параметры линейный слоев сети. [кол-во линейных слоев, кол-во нейронов в каждом слое]. в кол-во слоев включается слой на кол-во классов\n",
    " - class_qty - кол-во классов.\n",
    " - print_dim - печатает параметры тензора на выходе из соответствующего слоя.\n",
    "\n",
    "MaxPooling слой всегда имеет параметры kernel_size=2, stride=2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    'body_input': [224, 224, 3], # list height, width, channel\n",
    "    'conv_layers': [[1, 1, 1], [1,1,1], [2,1,1],[2,1,1], [1,1,1]], # list of lists. each layer should be list: qty conv layers, stride same or valid, padding\n",
    "    'linear_layers': [3, 256], # qty linear layers, qty neurons\n",
    "    'class_qty': [10],\n",
    "    'print_dim': True # True if you want to show how to change the tensor dimention via convolutional layers\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(params['conv_layers'])[:,0].sum() + params['linear_layers'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model name is VGG10_Adam_lr0.0003_b32_cos_sc60\n"
     ]
    }
   ],
   "source": [
    "n = cosine_cycles if scheduler_type == 'cos' else decay_steps\n",
    "model_name = f\"VGG{np.array(params['conv_layers'])[:,0].sum() + params['linear_layers'][0]}_{optimizer_type}_lr{learning_rate}_b{batch_size}_{scheduler_type}_sc{(num_epoch)//n}\"\n",
    "print(f'model name is {model_name}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VGG_like(nn.Module):\n",
    "\n",
    "    def __init__(self, params):\n",
    "        self.body_input = params['body_input']\n",
    "        self.conv_layers = params['conv_layers']\n",
    "        self.linear_layers = params['linear_layers']\n",
    "        self.class_qty = params['class_qty']\n",
    "        self.print_dim = params['print_dim']\n",
    "        \n",
    "        super().__init__()\n",
    "        \n",
    "        def conv_block(conv_layer, resolution=None, i=None, print_dim=False):\n",
    "            for qty in range(conv_layer[0]):\n",
    "                self.channels_out = min(64*(2**i), 512)\n",
    "                self.body.add_module(name='Block%2d_Conv_%d'%(i,qty), module=nn.Conv2d(\n",
    "                        self.channels_input, \n",
    "                        self.channels_out, \n",
    "                        kernel_size=3, \n",
    "                        stride=conv_layer[1], \n",
    "                        padding=conv_layer[2]))\n",
    "                self.body.add_module(name='Block%2d_Relu_%d'%(i,qty), module=nn.ReLU())\n",
    "                self.channels_input = self.channels_out\n",
    "                resolution = (resolution - 2 + conv_layer[2]*2) // conv_layer[1] \n",
    "                if print_dim: print('Tensor dim after conv layer is: ', [*resolution, self.channels_input])\n",
    "            self.body.add_module(name='Block%2d_MaxPool'%i, module=nn.MaxPool2d(kernel_size=2, stride=2))\n",
    "            resolution = resolution // 2 \n",
    "            if print_dim: print('Tensor dim after maxpool layer is: ', [*resolution, self.channels_input])\n",
    "            return resolution\n",
    "        \n",
    "        def linear_block(linear_layer, resolution):\n",
    "            self.input = resolution[0] * resolution[1] * min(64*(2**len(self.conv_layers)), 512) # resolution[0] * resolution[1] *\n",
    "            for i in range(self.linear_layers[0]-1):\n",
    "                self.head.add_module(name='Linear%2d'%i, module=nn.Linear(self.input, self.linear_layers[1]))\n",
    "                self.head.add_module(name='Dropout%2d'%i, module=nn.Dropout(.5))\n",
    "                self.head.add_module(name='Relu_%2d'%i, module=nn.ReLU())\n",
    "                self.input = linear_layer[1]\n",
    "            self.head.add_module(name='output',module=nn.Linear(self.linear_layers[1], self.class_qty[0]))\n",
    "        \n",
    "        self.body = nn.Sequential()\n",
    "        self.channels_input = self.body_input[2]\n",
    "        self.resolution = np.array([self.body_input[0], self.body_input[1]])\n",
    "        i = 0\n",
    "        for conv_layer in self.conv_layers:\n",
    "            self.resolution = conv_block(conv_layer, self.resolution, i, print_dim=self.print_dim)\n",
    "            i += 1\n",
    "\n",
    "        self.head = nn.Sequential()\n",
    "        linear_block(self.linear_layers, self.resolution)\n",
    "\n",
    "\n",
    "    def forward(self, input):\n",
    "        x = self.body(input)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        out = self.head(x)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Инициализируем модель с через конструктор"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor dim after conv layer is:  [224, 224, 64]\n",
      "Tensor dim after maxpool layer is:  [112, 112, 64]\n",
      "Tensor dim after conv layer is:  [112, 112, 128]\n",
      "Tensor dim after maxpool layer is:  [56, 56, 128]\n",
      "Tensor dim after conv layer is:  [56, 56, 256]\n",
      "Tensor dim after conv layer is:  [56, 56, 256]\n",
      "Tensor dim after maxpool layer is:  [28, 28, 256]\n",
      "Tensor dim after conv layer is:  [28, 28, 512]\n",
      "Tensor dim after conv layer is:  [28, 28, 512]\n",
      "Tensor dim after maxpool layer is:  [14, 14, 512]\n",
      "Tensor dim after conv layer is:  [14, 14, 512]\n",
      "Tensor dim after maxpool layer is:  [7, 7, 512]\n"
     ]
    }
   ],
   "source": [
    "model = VGG_like(params)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = train_tools.get_optimizer(model, optimizer_type, learning_rate)\n",
    "scheduler = train_tools.get_scheduler(optimizer, scheduler_type, step_size=num_epoch//decay_steps, cycle_len=num_epoch//cosine_cycles)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Загружаем модель на видеокарту."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "VGG_like(\n",
       "  (body): Sequential(\n",
       "    (Block 0_Conv_0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (Block 0_Relu_0): ReLU()\n",
       "    (Block 0_MaxPool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (Block 1_Conv_0): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (Block 1_Relu_0): ReLU()\n",
       "    (Block 1_MaxPool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (Block 2_Conv_0): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (Block 2_Relu_0): ReLU()\n",
       "    (Block 2_Conv_1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (Block 2_Relu_1): ReLU()\n",
       "    (Block 2_MaxPool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (Block 3_Conv_0): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (Block 3_Relu_0): ReLU()\n",
       "    (Block 3_Conv_1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (Block 3_Relu_1): ReLU()\n",
       "    (Block 3_MaxPool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (Block 4_Conv_0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (Block 4_Relu_0): ReLU()\n",
       "    (Block 4_MaxPool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (head): Sequential(\n",
       "    (Linear 0): Linear(in_features=25088, out_features=256, bias=True)\n",
       "    (Dropout 0): Dropout(p=0.5, inplace=False)\n",
       "    (Relu_ 0): ReLU()\n",
       "    (Linear 1): Linear(in_features=256, out_features=256, bias=True)\n",
       "    (Dropout 1): Dropout(p=0.5, inplace=False)\n",
       "    (Relu_ 1): ReLU()\n",
       "    (output): Linear(in_features=256, out_features=10, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda:5\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets_loader.create_dir(save_model_dir)\n",
    "datasets_loader.create_dir(metrics_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File with train metrics save to ./metrics/VGG10_Adam_lr0.0003_b32_cos_sc60.csv\n"
     ]
    }
   ],
   "source": [
    "cols_name = ['epoch', 'time', 'current_lr', 'loss', 'accuracy_train', 'accuracy_val']\n",
    "metrics_frame = pd.DataFrame(columns=cols_name)\n",
    "metrics_frame_file = (metrics_dir + model_name + '.csv')\n",
    "print(f'File with train metrics save to {metrics_frame_file}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Основной тренировочный цикл и подсчет метрик.\n",
    "    Основная метрика accuracy (топ1). Очень не хотелось бы получать ошибку на топ5 accuracy при 10 классах."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/120, Time: 52.89 sec, current_lr: 3.00e-04, Loss: 2.166, Accuracy_train: 0.244, Accuracy_val: 0.219\n",
      "Epoch 2/120, Time: 52.26 sec, current_lr: 2.99e-04, Loss: 2.101, Accuracy_train: 0.260, Accuracy_val: 0.259\n",
      "Epoch 5/120, Time: 51.64 sec, current_lr: 2.95e-04, Loss: 1.586, Accuracy_train: 0.433, Accuracy_val: 0.409\n",
      "Epoch 6/120, Time: 55.61 sec, current_lr: 2.93e-04, Loss: 1.662, Accuracy_train: 0.473, Accuracy_val: 0.567\n",
      "Epoch 7/120, Time: 54.38 sec, current_lr: 2.90e-04, Loss: 1.437, Accuracy_train: 0.557, Accuracy_val: 0.571\n",
      "Epoch 8/120, Time: 52.40 sec, current_lr: 2.87e-04, Loss: 1.324, Accuracy_train: 0.552, Accuracy_val: 0.603\n",
      "Epoch 9/120, Time: 52.36 sec, current_lr: 2.84e-04, Loss: 0.982, Accuracy_train: 0.598, Accuracy_val: 0.654\n",
      "Epoch 10/120, Time: 51.90 sec, current_lr: 2.80e-04, Loss: 1.099, Accuracy_train: 0.637, Accuracy_val: 0.671\n",
      "Epoch 11/120, Time: 52.31 sec, current_lr: 2.76e-04, Loss: 0.947, Accuracy_train: 0.637, Accuracy_val: 0.725\n",
      "Epoch 12/120, Time: 51.85 sec, current_lr: 2.71e-04, Loss: 1.373, Accuracy_train: 0.653, Accuracy_val: 0.682\n",
      "Epoch 13/120, Time: 52.29 sec, current_lr: 2.67e-04, Loss: 0.804, Accuracy_train: 0.691, Accuracy_val: 0.718\n",
      "Epoch 14/120, Time: 51.34 sec, current_lr: 2.61e-04, Loss: 1.018, Accuracy_train: 0.688, Accuracy_val: 0.752\n",
      "Epoch 15/120, Time: 52.19 sec, current_lr: 2.56e-04, Loss: 1.140, Accuracy_train: 0.703, Accuracy_val: 0.704\n",
      "Epoch 16/120, Time: 53.03 sec, current_lr: 2.50e-04, Loss: 1.311, Accuracy_train: 0.697, Accuracy_val: 0.743\n",
      "Epoch 17/120, Time: 52.12 sec, current_lr: 2.44e-04, Loss: 0.843, Accuracy_train: 0.713, Accuracy_val: 0.723\n",
      "Epoch 18/120, Time: 52.74 sec, current_lr: 2.38e-04, Loss: 1.196, Accuracy_train: 0.740, Accuracy_val: 0.724\n",
      "Epoch 19/120, Time: 52.61 sec, current_lr: 2.32e-04, Loss: 1.096, Accuracy_train: 0.727, Accuracy_val: 0.745\n",
      "Epoch 20/120, Time: 52.19 sec, current_lr: 2.25e-04, Loss: 0.818, Accuracy_train: 0.771, Accuracy_val: 0.808\n",
      "Epoch 21/120, Time: 52.01 sec, current_lr: 2.18e-04, Loss: 0.627, Accuracy_train: 0.779, Accuracy_val: 0.798\n",
      "Epoch 22/120, Time: 52.89 sec, current_lr: 2.11e-04, Loss: 0.712, Accuracy_train: 0.815, Accuracy_val: 0.808\n",
      "Epoch 23/120, Time: 53.26 sec, current_lr: 2.04e-04, Loss: 1.024, Accuracy_train: 0.819, Accuracy_val: 0.806\n",
      "Epoch 24/120, Time: 52.46 sec, current_lr: 1.96e-04, Loss: 0.921, Accuracy_train: 0.775, Accuracy_val: 0.808\n",
      "Epoch 25/120, Time: 52.25 sec, current_lr: 1.89e-04, Loss: 0.902, Accuracy_train: 0.807, Accuracy_val: 0.806\n",
      "Epoch 26/120, Time: 52.53 sec, current_lr: 1.81e-04, Loss: 1.271, Accuracy_train: 0.785, Accuracy_val: 0.796\n",
      "Epoch 27/120, Time: 52.11 sec, current_lr: 1.73e-04, Loss: 0.953, Accuracy_train: 0.803, Accuracy_val: 0.839\n",
      "Epoch 28/120, Time: 53.34 sec, current_lr: 1.66e-04, Loss: 0.499, Accuracy_train: 0.818, Accuracy_val: 0.799\n",
      "Epoch 29/120, Time: 52.57 sec, current_lr: 1.58e-04, Loss: 0.701, Accuracy_train: 0.834, Accuracy_val: 0.833\n",
      "Epoch 30/120, Time: 51.76 sec, current_lr: 1.50e-04, Loss: 0.284, Accuracy_train: 0.819, Accuracy_val: 0.811\n",
      "Epoch 31/120, Time: 52.98 sec, current_lr: 1.42e-04, Loss: 1.219, Accuracy_train: 0.857, Accuracy_val: 0.817\n",
      "Epoch 32/120, Time: 52.52 sec, current_lr: 1.34e-04, Loss: 0.721, Accuracy_train: 0.822, Accuracy_val: 0.826\n",
      "Epoch 33/120, Time: 52.32 sec, current_lr: 1.27e-04, Loss: 0.225, Accuracy_train: 0.856, Accuracy_val: 0.827\n",
      "Epoch 34/120, Time: 52.34 sec, current_lr: 1.19e-04, Loss: 0.299, Accuracy_train: 0.840, Accuracy_val: 0.836\n",
      "Epoch 35/120, Time: 52.89 sec, current_lr: 1.11e-04, Loss: 0.210, Accuracy_train: 0.857, Accuracy_val: 0.835\n",
      "Epoch 36/120, Time: 52.73 sec, current_lr: 1.04e-04, Loss: 0.403, Accuracy_train: 0.856, Accuracy_val: 0.841\n",
      "Epoch 37/120, Time: 53.20 sec, current_lr: 9.62e-05, Loss: 0.368, Accuracy_train: 0.860, Accuracy_val: 0.853\n",
      "Epoch 38/120, Time: 52.40 sec, current_lr: 8.90e-05, Loss: 0.421, Accuracy_train: 0.852, Accuracy_val: 0.857\n",
      "Epoch 39/120, Time: 52.80 sec, current_lr: 8.19e-05, Loss: 0.535, Accuracy_train: 0.857, Accuracy_val: 0.841\n",
      "Epoch 40/120, Time: 52.77 sec, current_lr: 7.50e-05, Loss: 0.222, Accuracy_train: 0.851, Accuracy_val: 0.849\n",
      "Epoch 41/120, Time: 53.97 sec, current_lr: 6.83e-05, Loss: 0.638, Accuracy_train: 0.859, Accuracy_val: 0.847\n",
      "Epoch 42/120, Time: 52.79 sec, current_lr: 6.18e-05, Loss: 0.274, Accuracy_train: 0.867, Accuracy_val: 0.846\n",
      "Epoch 43/120, Time: 51.83 sec, current_lr: 5.56e-05, Loss: 0.632, Accuracy_train: 0.875, Accuracy_val: 0.865\n",
      "Epoch 44/120, Time: 52.76 sec, current_lr: 4.96e-05, Loss: 0.791, Accuracy_train: 0.884, Accuracy_val: 0.860\n",
      "Epoch 45/120, Time: 52.39 sec, current_lr: 4.39e-05, Loss: 0.647, Accuracy_train: 0.888, Accuracy_val: 0.852\n",
      "Epoch 46/120, Time: 52.44 sec, current_lr: 3.85e-05, Loss: 0.248, Accuracy_train: 0.894, Accuracy_val: 0.852\n",
      "Epoch 47/120, Time: 52.92 sec, current_lr: 3.34e-05, Loss: 0.111, Accuracy_train: 0.863, Accuracy_val: 0.849\n",
      "Epoch 48/120, Time: 52.86 sec, current_lr: 2.86e-05, Loss: 0.586, Accuracy_train: 0.897, Accuracy_val: 0.845\n",
      "Epoch 49/120, Time: 52.49 sec, current_lr: 2.42e-05, Loss: 0.609, Accuracy_train: 0.888, Accuracy_val: 0.857\n",
      "Epoch 50/120, Time: 52.30 sec, current_lr: 2.01e-05, Loss: 0.503, Accuracy_train: 0.893, Accuracy_val: 0.869\n",
      "Epoch 51/120, Time: 51.93 sec, current_lr: 1.63e-05, Loss: 0.594, Accuracy_train: 0.881, Accuracy_val: 0.875\n",
      "Epoch 52/120, Time: 52.74 sec, current_lr: 1.30e-05, Loss: 0.222, Accuracy_train: 0.910, Accuracy_val: 0.840\n",
      "Epoch 53/120, Time: 52.34 sec, current_lr: 9.96e-06, Loss: 0.585, Accuracy_train: 0.882, Accuracy_val: 0.849\n",
      "Epoch 54/120, Time: 52.13 sec, current_lr: 7.34e-06, Loss: 0.363, Accuracy_train: 0.892, Accuracy_val: 0.876\n",
      "Epoch 55/120, Time: 52.88 sec, current_lr: 5.11e-06, Loss: 0.267, Accuracy_train: 0.894, Accuracy_val: 0.860\n",
      "Epoch 56/120, Time: 53.36 sec, current_lr: 3.28e-06, Loss: 0.198, Accuracy_train: 0.906, Accuracy_val: 0.854\n",
      "Epoch 57/120, Time: 73.82 sec, current_lr: 1.85e-06, Loss: 0.518, Accuracy_train: 0.885, Accuracy_val: 0.865\n",
      "Epoch 58/120, Time: 51.93 sec, current_lr: 8.22e-07, Loss: 0.203, Accuracy_train: 0.915, Accuracy_val: 0.876\n",
      "Epoch 59/120, Time: 52.91 sec, current_lr: 2.06e-07, Loss: 0.443, Accuracy_train: 0.885, Accuracy_val: 0.863\n",
      "Epoch 60/120, Time: 52.64 sec, current_lr: 3.00e-04, Loss: 0.454, Accuracy_train: 0.881, Accuracy_val: 0.875\n",
      "Epoch 61/120, Time: 52.14 sec, current_lr: 3.00e-04, Loss: 1.044, Accuracy_train: 0.790, Accuracy_val: 0.853\n",
      "Epoch 62/120, Time: 52.93 sec, current_lr: 2.99e-04, Loss: 0.367, Accuracy_train: 0.841, Accuracy_val: 0.843\n",
      "Epoch 63/120, Time: 52.95 sec, current_lr: 2.98e-04, Loss: 0.735, Accuracy_train: 0.835, Accuracy_val: 0.838\n",
      "Epoch 64/120, Time: 52.45 sec, current_lr: 2.97e-04, Loss: 0.513, Accuracy_train: 0.834, Accuracy_val: 0.823\n",
      "Epoch 65/120, Time: 52.73 sec, current_lr: 2.95e-04, Loss: 0.383, Accuracy_train: 0.841, Accuracy_val: 0.855\n",
      "Epoch 66/120, Time: 52.50 sec, current_lr: 2.93e-04, Loss: 0.522, Accuracy_train: 0.840, Accuracy_val: 0.828\n",
      "Epoch 67/120, Time: 53.63 sec, current_lr: 2.90e-04, Loss: 0.787, Accuracy_train: 0.844, Accuracy_val: 0.830\n",
      "Epoch 68/120, Time: 52.84 sec, current_lr: 2.87e-04, Loss: 0.573, Accuracy_train: 0.859, Accuracy_val: 0.825\n",
      "Epoch 69/120, Time: 52.84 sec, current_lr: 2.84e-04, Loss: 0.460, Accuracy_train: 0.845, Accuracy_val: 0.857\n",
      "Epoch 70/120, Time: 52.54 sec, current_lr: 2.80e-04, Loss: 0.664, Accuracy_train: 0.845, Accuracy_val: 0.861\n",
      "Epoch 71/120, Time: 52.33 sec, current_lr: 2.76e-04, Loss: 0.286, Accuracy_train: 0.841, Accuracy_val: 0.831\n",
      "Epoch 72/120, Time: 51.86 sec, current_lr: 2.71e-04, Loss: 0.498, Accuracy_train: 0.859, Accuracy_val: 0.829\n",
      "Epoch 73/120, Time: 53.10 sec, current_lr: 2.67e-04, Loss: 0.475, Accuracy_train: 0.875, Accuracy_val: 0.848\n",
      "Epoch 74/120, Time: 52.61 sec, current_lr: 2.61e-04, Loss: 0.703, Accuracy_train: 0.911, Accuracy_val: 0.853\n",
      "Epoch 75/120, Time: 52.68 sec, current_lr: 2.56e-04, Loss: 0.226, Accuracy_train: 0.880, Accuracy_val: 0.862\n",
      "Epoch 76/120, Time: 52.39 sec, current_lr: 2.50e-04, Loss: 0.383, Accuracy_train: 0.885, Accuracy_val: 0.878\n",
      "Epoch 77/120, Time: 52.85 sec, current_lr: 2.44e-04, Loss: 0.723, Accuracy_train: 0.861, Accuracy_val: 0.840\n",
      "Epoch 78/120, Time: 52.76 sec, current_lr: 2.38e-04, Loss: 0.307, Accuracy_train: 0.881, Accuracy_val: 0.871\n",
      "Epoch 79/120, Time: 54.45 sec, current_lr: 2.32e-04, Loss: 0.375, Accuracy_train: 0.893, Accuracy_val: 0.847\n",
      "Epoch 80/120, Time: 54.23 sec, current_lr: 2.25e-04, Loss: 0.479, Accuracy_train: 0.880, Accuracy_val: 0.845\n",
      "Epoch 81/120, Time: 54.06 sec, current_lr: 2.18e-04, Loss: 0.687, Accuracy_train: 0.892, Accuracy_val: 0.865\n",
      "Epoch 82/120, Time: 53.01 sec, current_lr: 2.11e-04, Loss: 0.402, Accuracy_train: 0.893, Accuracy_val: 0.836\n",
      "Epoch 83/120, Time: 53.97 sec, current_lr: 2.04e-04, Loss: 0.932, Accuracy_train: 0.892, Accuracy_val: 0.876\n",
      "Epoch 84/120, Time: 54.97 sec, current_lr: 1.96e-04, Loss: 0.670, Accuracy_train: 0.908, Accuracy_val: 0.851\n",
      "Epoch 85/120, Time: 53.46 sec, current_lr: 1.89e-04, Loss: 0.382, Accuracy_train: 0.897, Accuracy_val: 0.877\n",
      "Epoch 86/120, Time: 53.98 sec, current_lr: 1.81e-04, Loss: 0.279, Accuracy_train: 0.896, Accuracy_val: 0.851\n",
      "Epoch 87/120, Time: 54.64 sec, current_lr: 1.73e-04, Loss: 0.274, Accuracy_train: 0.896, Accuracy_val: 0.860\n",
      "Epoch 88/120, Time: 52.68 sec, current_lr: 1.66e-04, Loss: 0.583, Accuracy_train: 0.909, Accuracy_val: 0.853\n",
      "Epoch 89/120, Time: 53.27 sec, current_lr: 1.58e-04, Loss: 0.297, Accuracy_train: 0.904, Accuracy_val: 0.850\n",
      "Epoch 90/120, Time: 53.50 sec, current_lr: 1.50e-04, Loss: 0.293, Accuracy_train: 0.915, Accuracy_val: 0.870\n",
      "Epoch 91/120, Time: 52.75 sec, current_lr: 1.42e-04, Loss: 0.361, Accuracy_train: 0.935, Accuracy_val: 0.847\n",
      "Epoch 92/120, Time: 52.35 sec, current_lr: 1.34e-04, Loss: 0.315, Accuracy_train: 0.898, Accuracy_val: 0.849\n",
      "Epoch 93/120, Time: 52.87 sec, current_lr: 1.27e-04, Loss: 0.287, Accuracy_train: 0.922, Accuracy_val: 0.870\n",
      "Epoch 94/120, Time: 73.01 sec, current_lr: 1.19e-04, Loss: 0.356, Accuracy_train: 0.930, Accuracy_val: 0.875\n",
      "Epoch 95/120, Time: 52.48 sec, current_lr: 1.11e-04, Loss: 0.199, Accuracy_train: 0.917, Accuracy_val: 0.878\n",
      "Epoch 96/120, Time: 52.24 sec, current_lr: 1.04e-04, Loss: 0.333, Accuracy_train: 0.906, Accuracy_val: 0.859\n",
      "Epoch 97/120, Time: 52.35 sec, current_lr: 9.62e-05, Loss: 0.407, Accuracy_train: 0.947, Accuracy_val: 0.863\n",
      "Epoch 98/120, Time: 52.58 sec, current_lr: 8.90e-05, Loss: 0.084, Accuracy_train: 0.929, Accuracy_val: 0.878\n",
      "Epoch 99/120, Time: 53.45 sec, current_lr: 8.19e-05, Loss: 0.053, Accuracy_train: 0.923, Accuracy_val: 0.879\n",
      "Epoch 100/120, Time: 52.67 sec, current_lr: 7.50e-05, Loss: 0.354, Accuracy_train: 0.915, Accuracy_val: 0.860\n",
      "Epoch 101/120, Time: 52.23 sec, current_lr: 6.83e-05, Loss: 0.266, Accuracy_train: 0.946, Accuracy_val: 0.864\n",
      "Epoch 102/120, Time: 53.00 sec, current_lr: 6.18e-05, Loss: 0.351, Accuracy_train: 0.955, Accuracy_val: 0.878\n",
      "Epoch 103/120, Time: 73.68 sec, current_lr: 5.56e-05, Loss: 0.197, Accuracy_train: 0.938, Accuracy_val: 0.865\n",
      "Epoch 104/120, Time: 53.82 sec, current_lr: 4.96e-05, Loss: 0.308, Accuracy_train: 0.930, Accuracy_val: 0.842\n",
      "Epoch 105/120, Time: 74.74 sec, current_lr: 4.39e-05, Loss: 0.454, Accuracy_train: 0.929, Accuracy_val: 0.882\n",
      "Epoch 106/120, Time: 53.59 sec, current_lr: 3.85e-05, Loss: 0.078, Accuracy_train: 0.942, Accuracy_val: 0.871\n",
      "Epoch 107/120, Time: 52.98 sec, current_lr: 3.34e-05, Loss: 0.103, Accuracy_train: 0.941, Accuracy_val: 0.872\n",
      "Epoch 108/120, Time: 73.53 sec, current_lr: 2.86e-05, Loss: 0.143, Accuracy_train: 0.937, Accuracy_val: 0.882\n",
      "Epoch 109/120, Time: 53.05 sec, current_lr: 2.42e-05, Loss: 0.493, Accuracy_train: 0.942, Accuracy_val: 0.858\n",
      "Epoch 110/120, Time: 52.80 sec, current_lr: 2.01e-05, Loss: 0.137, Accuracy_train: 0.942, Accuracy_val: 0.878\n",
      "Epoch 111/120, Time: 74.62 sec, current_lr: 1.63e-05, Loss: 0.281, Accuracy_train: 0.939, Accuracy_val: 0.884\n",
      "Epoch 112/120, Time: 53.32 sec, current_lr: 1.30e-05, Loss: 0.090, Accuracy_train: 0.950, Accuracy_val: 0.883\n",
      "Epoch 113/120, Time: 53.02 sec, current_lr: 9.96e-06, Loss: 0.030, Accuracy_train: 0.930, Accuracy_val: 0.866\n",
      "Epoch 114/120, Time: 52.37 sec, current_lr: 7.34e-06, Loss: 0.171, Accuracy_train: 0.938, Accuracy_val: 0.875\n",
      "Epoch 115/120, Time: 52.93 sec, current_lr: 5.11e-06, Loss: 0.601, Accuracy_train: 0.951, Accuracy_val: 0.884\n",
      "Epoch 116/120, Time: 52.73 sec, current_lr: 3.28e-06, Loss: 0.141, Accuracy_train: 0.935, Accuracy_val: 0.882\n",
      "Epoch 117/120, Time: 73.37 sec, current_lr: 1.85e-06, Loss: 0.107, Accuracy_train: 0.958, Accuracy_val: 0.882\n",
      "Epoch 118/120, Time: 53.09 sec, current_lr: 8.22e-07, Loss: 0.014, Accuracy_train: 0.945, Accuracy_val: 0.877\n",
      "Epoch 119/120, Time: 52.76 sec, current_lr: 2.06e-07, Loss: 0.083, Accuracy_train: 0.945, Accuracy_val: 0.877\n",
      "Epoch 120/120, Time: 52.26 sec, current_lr: 3.00e-04, Loss: 0.467, Accuracy_train: 0.943, Accuracy_val: 0.881\n"
     ]
    }
   ],
   "source": [
    "torch.set_num_threads(16)\n",
    "\n",
    "for epoch in range(num_epoch):\n",
    "    # train cycle\n",
    "    model.train()\n",
    "    start_time = time.time()\n",
    "    for data in trainloader:\n",
    "        loss, outputs = train_tools.make_step(data, optimizer, model, criterion, device)\n",
    "    scheduler.step()\n",
    "    \n",
    "    # metrics calc\n",
    "    model.eval()\n",
    "    accuracy_train = train_tools.approx_accuracy(trainloader, model, device, fraction=.08)\n",
    "    accuracy_val = train_tools.approx_accuracy(testloader, model, device, fraction=.25)\n",
    "    \n",
    "    if accuracy_val >= .88 and accuracy_val >= metrics_frame['accuracy_val'].max():\n",
    "        accuracy_val = train_tools.true_accuracy(testloader, model, device)\n",
    "\n",
    "    end_time = time.time()\n",
    "    metrics = {'epoch': epoch + 1,\n",
    "               'time': end_time - start_time,\n",
    "               'current_lr': [group['lr'] for group in optimizer.param_groups][0],\n",
    "               'loss': float(loss),\n",
    "               'accuracy_train': accuracy_train,\n",
    "               'accuracy_val': accuracy_val,\n",
    "               }\n",
    "\n",
    "    print(\"Epoch {}/{}, Time: {:.2f} sec, current_lr: {:.2e}, Loss: {:.3f}, Accuracy_train: {:.3f}, Accuracy_val: {:.3f}\".\n",
    "          format(metrics['epoch'], num_epoch, metrics['time'], metrics['current_lr'], metrics['loss'], metrics['accuracy_train'], metrics['accuracy_val']))\n",
    "    \n",
    "    metrics_frame = metrics_frame.append(pd.DataFrame.from_dict(metrics, orient='index').T)\n",
    "    metrics_frame.to_csv(metrics_frame_file, index=False)\n",
    "    \n",
    "    if save_best_model:\n",
    "        if metrics['accuracy_val'] == metrics_frame['accuracy_val'].max():\n",
    "            torch.save(model, save_model_dir + model_name + '.pt')\n",
    "if not save_best_model:\n",
    "    torch.save(model, save_model_dir + model_name + '.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>epoch</th>\n",
       "      <th>time</th>\n",
       "      <th>current_lr</th>\n",
       "      <th>loss</th>\n",
       "      <th>accuracy_train</th>\n",
       "      <th>accuracy_val</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>111.0</td>\n",
       "      <td>74.622555</td>\n",
       "      <td>0.000016</td>\n",
       "      <td>0.280942</td>\n",
       "      <td>0.939234</td>\n",
       "      <td>0.884331</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   epoch       time  current_lr      loss  accuracy_train  accuracy_val\n",
       "0  111.0  74.622555    0.000016  0.280942        0.939234      0.884331"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics_frame[metrics_frame['accuracy_val'] == metrics_frame['accuracy_val'].max()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
