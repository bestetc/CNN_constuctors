{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pipeline ResNet-like\n",
    "### В пайплайне используется контруктор ResNet подобных сетей\n",
    "- ResNet сильно оверфитится на Imahenette датасете. \n",
    "- Accuracy на тестовом датасете состоавляет 0.92"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from torch import nn\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyper params\n",
    "batch_size = 32\n",
    "num_epoch = 600\n",
    "learning_rate = 0.1 # 0.1 * batch_size / 256\n",
    "sheduler_type = 'cosine' # 'cosine' or 'step'\n",
    "sheduler_cycle = 6\n",
    "optimizer_type = 'SGD' # 'SGD' or 'Adam'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Создаем DataLoader попутно предобрабатывая данные\n",
    "- Загрузку датасета можно найти в VGG_like.ipynb\n",
    "- Предварительный смотр данных можно найти в VGG_like.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/torchvision/transforms/transforms.py:704: UserWarning: The use of the transforms.RandomSizedCrop transform is deprecated, please use transforms.RandomResizedCrop instead.\n",
      "  \"please use transforms.RandomResizedCrop instead.\")\n"
     ]
    }
   ],
   "source": [
    "from torchvision import transforms, datasets\n",
    "\n",
    "train_transform = transforms.Compose([\n",
    "        transforms.Resize((260,260)),\n",
    "        transforms.RandomSizedCrop(224),\n",
    "#         transforms.ColorJitter(brightness=0.4, contrast=0.4, saturation=0.4, hue=0.2),\n",
    "#         transforms.RandomResizedCrop(224, scale=(0.08, 1.0), ratio=(0.75, 1.3333333333333333)),\n",
    "        transforms.RandomHorizontalFlip(.5),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                             std=[0.229, 0.224, 0.225])\n",
    "    ])\n",
    "test_transform = transforms.Compose([\n",
    "        transforms.Resize((224,224)),\n",
    "#         transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                             std=[0.229, 0.224, 0.225])\n",
    "    ])\n",
    "\n",
    "trainset = datasets.ImageFolder(root='../imagenette/imagenette2-320/train/', transform=train_transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size,\n",
    "                                          shuffle=True)\n",
    "testset = datasets.ImageFolder(root='../imagenette/imagenette2-320/val/', transform=test_transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, #batch_size=batch_size,\n",
    "                                         shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "297"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(trainloader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Создаем конструктор ResNet-like сетей.\n",
    "\n",
    "### Конструктор представляет собой класс, который ожидает на вход следующие параметры:\n",
    "\n",
    " - layers - список с количеством стандартных блоков по слоям\n",
    " - num_classes - количество классов\n",
    " - bottleneck - определяет использование стандартных блоков или 'bottleneck' блоков \n",
    "\n",
    "(!) Конструктор ожидает на вход изображение с разрешением 224х224х3\n",
    "\n",
    "Примеры стандартных сетей:\n",
    "ResNet-18: \n",
    "model = ResNet_like(layers=[2,2,2,2], num_classes=10, bottleneck=False)\n",
    "\n",
    "ResNet-36: \n",
    "model = ResNet_like(layers=[3,4,6,3], num_classes=10, bottleneck=False)\n",
    "\n",
    "ResNet-50:\n",
    "model = ResNet_like(layers=[3,4,6,3], num_classes=10, bottleneck=True)\n",
    "\n",
    "ResNet-101:\n",
    "model = ResNet_like(layers=[3,4,23,3], num_classes=10, bottleneck=True)\n",
    "\n",
    "ResNet-152:\n",
    "model = ResNet_like(layers=[3,8,36,3], num_classes=10, bottleneck=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Выносим в функции сверточные слои для уменьшения количества букв в коде"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv1x1(in_channels, out_channels, stride=1):\n",
    "    return nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=stride, padding=0)\n",
    "\n",
    "def conv3x3(in_channels, out_channels, stride=1,padding=1):\n",
    "    return nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=stride, padding=padding)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Задаем базовые блоки через классы.\n",
    "Класс NormalBlock собирает стандартный ResNet блок с skipconnection'ом\n",
    "Класс BottleneckBlock собирает Bottleneck ResNet блок с skipconnection'ом\n",
    "\n",
    "Каждый класс ожидает параметры:\n",
    " - num_layer - порядковый номер слоя, в котором будет использоваться данных блок. В стандартной ResNet архитектуре блоки используются со второго слоя.\n",
    " - downsample - определяет тип downsampling'а.\n",
    "     - 0 - downsampling не используется\n",
    "     - 1 - downsampling используется в блоке, где уменьшается разрешение и увеличивается кол-во каналов\n",
    "     - -1 - downsampling используется в блоке, где разрешение не уменьшается, но увеличивается кол-во каналов (обычно последний слой)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NormalBlock(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        num_layer,\n",
    "        downsample = 0,\n",
    "        \n",
    "    ):\n",
    "        super(NormalBlock, self).__init__()\n",
    "        self.use_downsample = downsample\n",
    "        if num_layer == 2 and downsample == 1:\n",
    "            self.in_channels = 16*(2**num_layer)\n",
    "        elif num_layer > 2 and downsample != 0:\n",
    "            self.in_channels = 16*(2**(num_layer-1))\n",
    "        elif downsample == 0: \n",
    "            self.in_channels = 16*(2**num_layer)\n",
    "            \n",
    "        self.out_channels = 16*(2**num_layer)\n",
    "        \n",
    "        if downsample == 1:\n",
    "            self.downsample = nn.Sequential(\n",
    "                conv1x1(self.in_channels, self.out_channels, stride=2),\n",
    "                nn.BatchNorm2d(self.out_channels))\n",
    "            self.maxpool = nn.MaxPool2d(kernel_size=2,stride=2, padding=0)\n",
    "        elif downsample == -1:\n",
    "            self.downsample = conv1x1(self.in_channels, self.out_channels, stride=1)\n",
    "        \n",
    "        self.conv1 = conv3x3(self.in_channels, self.out_channels)\n",
    "        self.in_channels = self.out_channels\n",
    "        self.bn1 = nn.BatchNorm2d(self.out_channels)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.conv2 = conv3x3(self.in_channels, self.out_channels)\n",
    "        self.bn2 = nn.BatchNorm2d(self.out_channels)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        skip = x\n",
    "#         print('Block input',x.shape)\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "#         print('Block before skip',out.shape)\n",
    "\n",
    "        if self.use_downsample != 0:\n",
    "#             print('Before downsample',out.shape, skip.shape)\n",
    "            if self.use_downsample == 1:\n",
    "                out = self.maxpool(out)\n",
    "            skip = self.downsample(x)\n",
    "#             print('After downsample',out.shape, skip.shape)\n",
    "        out += skip\n",
    "        out = self.relu(out)\n",
    "\n",
    "        return out\n",
    "\n",
    "class BottleneckBlock(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        num_layer,\n",
    "        downsample = 0\n",
    "        \n",
    "    ):\n",
    "        super(BottleneckBlock, self).__init__()\n",
    "        \n",
    "        self.use_downsample = downsample\n",
    "        if num_layer == 2 and downsample == 1:\n",
    "            self.in_channels = 16*(2**num_layer)\n",
    "        elif num_layer > 2 and downsample != 0:\n",
    "            self.in_channels = 16*(2**(num_layer-1))*4\n",
    "        elif downsample == 0: \n",
    "            self.in_channels = 16*(2**num_layer)*4\n",
    "            \n",
    "        self.out_channels = 16*(2**num_layer)\n",
    "        \n",
    "        if downsample == 1:\n",
    "            self.downsample = nn.Sequential(\n",
    "                conv1x1(self.in_channels, self.out_channels, stride=2),\n",
    "                nn.BatchNorm2d(self.out_channels))\n",
    "            self.maxpool = nn.MaxPool2d(kernel_size=2,stride=2, padding=0)\n",
    "        elif downsample == -1:\n",
    "            self.downsample = nn.Sequential(\n",
    "                conv1x1(self.in_channels, self.out_channels, stride=1))\n",
    "   \n",
    "        if downsample == 1:\n",
    "            self.downsample = nn.Sequential(\n",
    "                conv1x1(self.in_channels, self.out_channels*4, stride=2),\n",
    "                nn.BatchNorm2d(self.out_channels*4))\n",
    "            self.maxpool = nn.MaxPool2d(kernel_size=2,stride=2, padding=0)\n",
    "        elif downsample == -1:\n",
    "            self.downsample = conv1x1(self.in_channels, self.out_channels*4, stride=1)\n",
    "        \n",
    "        self.conv1 = conv1x1(self.in_channels, self.out_channels)\n",
    "        self.in_channels = self.out_channels\n",
    "        self.bn1 = nn.BatchNorm2d(self.out_channels)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.conv2 = conv3x3(self.in_channels, self.out_channels)\n",
    "        self.bn2 = nn.BatchNorm2d(self.out_channels)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.out_channels = 16*(2**num_layer)*4\n",
    "        self.conv3 = conv1x1(self.in_channels, self.out_channels)\n",
    "        self.bn3 = nn.BatchNorm2d(self.out_channels)\n",
    "        self.in_channels = self.out_channels\n",
    "        \n",
    "    def forward(self, x):\n",
    "        skip = x\n",
    "        \n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.conv3(out)\n",
    "        out = self.bn3(out)\n",
    "\n",
    "        if self.use_downsample != 0:\n",
    "#             print(out.shape, x.shape)\n",
    "            if self.use_downsample == 1:\n",
    "                out = self.maxpool(out)\n",
    "            skip = self.downsample(x)\n",
    "#             print(out.shape, x.shape)\n",
    "        out += skip\n",
    "        out = self.relu(out)\n",
    "            \n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Класс конструктор ResNet подобных архитектур"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResNet_like(nn.Module):\n",
    "\n",
    "    def __init__(self, \n",
    "                 layers, \n",
    "                 num_classes,\n",
    "                 bottleneck,\n",
    "                 \n",
    "                 ):\n",
    "        \n",
    "        super(ResNet_like, self).__init__()\n",
    "        self.first = nn.Sequential(\n",
    "            nn.Conv2d(3, 64, kernel_size=7, stride=2, padding=3),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2, padding=1))\n",
    "        \n",
    "        self.body = nn.Sequential()\n",
    "        if bottleneck == True:\n",
    "            for num, layer in enumerate(layers):\n",
    "                for block in range(layer):\n",
    "                    if block == 0  and num < len(layers) - 1:\n",
    "                        downsample = 1\n",
    "                    elif block == 0 and num == len(layers) - 1:\n",
    "                        downsample = -1\n",
    "                    elif block != 0:  \n",
    "                        downsample = 0\n",
    "                    self.body.add_module(name='block_%d_%d'%(num+2,block+1), module=BottleneckBlock(num+2, downsample))\n",
    "        elif bottleneck == False:\n",
    "            for num, layer in enumerate(layers):\n",
    "                for block in range(layer):\n",
    "                    if block == 0  and num < len(layers) - 1:\n",
    "                        downsample = 1\n",
    "                    elif block == 0 and num == len(layers) - 1:\n",
    "                        downsample = -1\n",
    "                    elif block != 0:  \n",
    "                        downsample = 0\n",
    "                    self.body.add_module(name='block_%d_%d'%(num+2,block+1), module=NormalBlock(num+2, downsample))\n",
    "        \n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((1,1))\n",
    "        if bottleneck == True:\n",
    "            self.linear_input = 32*(2**(len(layers)))*4\n",
    "        else:\n",
    "            self.linear_input = 32*(2**(len(layers)))\n",
    "        self.linear = nn.Linear(self.linear_input, num_classes)\n",
    "        \n",
    "    def forward(self, x):\n",
    "\n",
    "        x = self.first(x)\n",
    "        x = self.body(x)\n",
    "#         print('Shape input avgpool:', x.shape)\n",
    "        x = self.avgpool(x)\n",
    "#         print('Shape input linear:', x.shape)\n",
    "        x = x.view(x.size(0), -1)\n",
    "#         print('Shape input linear:', x.shape)\n",
    "        x = self.linear(x)\n",
    "#         x = self.final(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Инициализируем модель с через конструктор"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ResNet_like(layers=[2,2,2,2], num_classes=10, bottleneck=True)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "if optimizer_type == 'SGD':\n",
    "    optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate, weight_decay=0.0001, momentum=0.9)\n",
    "elif optimizer_type == 'Adam':\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate, betas=(0.95, 0.99), eps=1e-06, weight_decay=0.0001, amsgrad=False)\n",
    "\n",
    "if sheduler_type == 'step':\n",
    "    scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=num_epoch//sheduler_cycle, gamma=0.1)\n",
    "elif sheduler_type == 'cosine':\n",
    "    scheduler_warmup = torch.optim.lr_scheduler.CyclicLR(optimizer, base_lr=0.001, max_lr=0.1)\n",
    "    scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, num_epoch//sheduler_cycle, eta_min=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ячейча используется для запуска реализации ResNet в библиотеке PyTorch для сравнения с конструктором."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from torchvision.models import resnet34\n",
    "# model = resnet34(num_classes=10)\n",
    "# criterion = nn.CrossEntropyLoss()\n",
    "# optimizer = torch.optim.SGD(model.parameters(), lr=0.learning_rate, momentum=0.9)\n",
    "# # optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate, betas=(0.9, 0.999), eps=1e-08, weight_decay=0, amsgrad=False)\n",
    "# # scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=40, gamma=0.1)\n",
    "# scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, num_epoch, eta_min=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Загружаем модель на видеокарту."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:2\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ResNet_like(\n",
       "  (first): Sequential(\n",
       "    (0): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3))\n",
       "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (body): Sequential(\n",
       "    (block_2_1): BottleneckBlock(\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(2, 2))\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (maxpool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU()\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (block_2_2): BottleneckBlock(\n",
       "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU()\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (block_3_1): BottleneckBlock(\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2))\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (maxpool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU()\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (block_3_2): BottleneckBlock(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU()\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (block_4_1): BottleneckBlock(\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2))\n",
       "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (maxpool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU()\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (block_4_2): BottleneckBlock(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU()\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (block_5_1): BottleneckBlock(\n",
       "      (downsample): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU()\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (block_5_2): BottleneckBlock(\n",
       "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU()\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (linear): Linear(in_features=2048, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda:2\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_name = ['epoch', 'time', 'current_lr', 'loss', 'accuracy_train', 'accuracy_val']\n",
    "metrics_frame = pd.DataFrame(columns=cols_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Основной тренировочный цикл и подсчет метрик.\n",
    "    Основная метрика accuracy (топ1). Очень не хотелось бы получать ошибку на топ5 accuracy при 10 классах."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/600, Time: 120.76 sec, current_lr: 1.00e-03, Loss: 1.321, Accuracy_train: 0.471, Accuracy_val: 0.510\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(num_epoch):  # loop over the dataset multiple times\n",
    "\n",
    "    model.train()\n",
    "    start_time = time.time()\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "       \n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "#         inputs, labels = data\n",
    "#         print(data[1])\n",
    "        inputs, labels = data[0].to(device), data[1].to(device)\n",
    "#         print(labels)\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "       \n",
    "        # forward + backward + optimize\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "#         print('Loss: ', loss)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    scheduler.step()\n",
    "    \n",
    "    #Accuracy train and val\n",
    "    model.eval()\n",
    "    correct_train, correct_val = 0, 0\n",
    "    total_train, total_val = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in trainloader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            outputs = outputs.to(device)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total_train += labels.size(0)\n",
    "            correct_train += (predicted == labels).sum().item()\n",
    "        for images, labels in testloader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            outputs = outputs.to(device)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total_val += labels.size(0)\n",
    "            correct_val += (predicted == labels).sum().item()\n",
    "    end_time = time.time()\n",
    "    metrics = {'epoch': epoch+1,\n",
    "       'time': end_time - start_time,\n",
    "       'current_lr': scheduler.get_last_lr()[0],\n",
    "       'loss': float(loss),\n",
    "       'accuracy_train': correct_train/total_train,\n",
    "       'accuracy_val': correct_val/total_val\n",
    "      }\n",
    "    print(\"Epoch {}/{}, Time: {:.2f} sec, current_lr: {:.2e}, Loss: {:.3f}, Accuracy_train: {:.3f}, Accuracy_val: {:.3f}\".\n",
    "          format(metrics['epoch'], num_epoch, metrics['time'], metrics['current_lr'], metrics['loss'], metrics['accuracy_train'], metrics['accuracy_val']))\n",
    "    \n",
    "    metrics_frame = metrics_frame.append(pd.DataFrame.from_dict(metrics,orient='index').T)\n",
    "    metrics_frame.to_csv('./metrics/ResNet_constructor_metrics.csv',index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
