{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ResNet Constructor. Версия 2\n",
    "Данный ноутбук содержит контруктор ResNet подобных сетей и пайплайн для работы с ним."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pipeline\n",
    "Pipeline служит для проверки работы конструктора на датасете Imagenette\n",
    "- accuracy на тестовой части датасета Imagenette составляет 0.92\n",
    "- в pipeline'e реализовано сохранения метрик и модели "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from torch import nn\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Гиперпараметры обучения\n",
    "- batch_size: кол-во изображений в одном батче. Предел зависит от кол-ва памяти на видеокарте\n",
    "- num_epoch: кол-во эпох обучения.\n",
    "- learning_rate: скорость обучения.\n",
    "- optimizer_type: тип оптимизатора, использующегося для обновления весов сети. Может быть 'SGD' или 'Adam'\n",
    "\n",
    "<b>Архитектура сети:\n",
    " - layers - список с количеством стандартных блоков по слоям\n",
    " - num_classes - количество классов\n",
    " - bottleneck - определяет использование стандартных блоков или 'bottleneck' блоков <br>\n",
    "\n",
    "(!) Конструктор ожидает на вход изображение с разрешением 224х224х3\n",
    "\n",
    "Примеры стандартных сетей:<br>\n",
    "<b>ResNet-18: </b> <br> \n",
    "model = ResNet_like(layers=[2,2,2,2], bottleneck=False, num_classes=10)\n",
    "\n",
    "<b>ResNet-36: </b> <br> \n",
    "model = ResNet_like(resnet_layers=[3,4,6,3], bottleneck=False, num_classes=10)\n",
    "\n",
    "<b>ResNet-50: </b> <br> \n",
    "model = ResNet_like(resnet_layers=[3,4,6,3], bottleneck=True, num_classes=10)\n",
    "\n",
    "<b>ResNet-101: </b> <br> \n",
    "model = ResNet_like(resnet_layers=[3,4,23,3], bottleneck=True, num_classes=10)\n",
    "\n",
    "<b>ResNet-152: </b> <br> \n",
    "model = ResNet_like(resnet_layers=[3,8,36,3], bottleneck=True, num_classes=10)\n",
    "    \n",
    "<b>Настройка изменения learning rate в течении обучения. </b><br> \n",
    "Реализовано две стратегии 'cos' - согласно функции косинуса и 'step' - ступенчатое уменьшение в 10 раз через равные промежутки.\n",
    "- sheduler_type: задает стратегию. может быть 'cos' или 'step'\n",
    "- sheduler_cycle: задает кол-во циклов изменения learning rate. Должно быть меньше или равно num_epoch<br> \n",
    "Для 'cos' интерпритируется как кол-во циклов убывания learning rate с возвратом к стартовому learning rate в начале нового цикла<br>\n",
    "Для 'step' интерпритируется как кол-во уменьшений learning rate\n",
    "\n",
    "Прочее\n",
    "- dataset_path: путь к папке с датасетом"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "num_epoch = 600\n",
    "learning_rate = 0.1\n",
    "optimizer_type = 'SGD'\n",
    "save_best_model = True\n",
    "\n",
    "# resnet architecture\n",
    "resnet_layers = [3,4,6,4]\n",
    "bottleneck = True\n",
    "num_classes = 10\n",
    "\n",
    "# learning_rate_decay\n",
    "sheduler_type = 'cos'\n",
    "sheduler_cycle = 1\n",
    "\n",
    "dataset_path = '../imagenette/imagenette2-320/'\n",
    "save_model_dir = './models/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Задаем название модели, которое будет фигурировать в названии сохраненных файлов метрики и модели<br>\n",
    "Название модели является производным от гиперпараметров"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ResNet18_SGD_lr0.1_b32_cos_sc1'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if bottleneck == True:\n",
    "    model_name = f'ResNet{sum(resnet_layers)*3+2}_{optimizer_type}_lr{learning_rate}_b{batch_size}_{sheduler_type}_sc{num_epoch//sheduler_cycle}'\n",
    "elif bottleneck == False:\n",
    "    model_name = f'ResNet{sum(resnet_layers)*2+2}_{optimizer_type}_lr{learning_rate}_b{batch_size}_{sheduler_type}_sc{num_epoch//sheduler_cycle}'\n",
    "model_name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Создаем DataLoader попутно предобрабатывая данные\n",
    "- Загрузку датасета можно найти в [VGG_torch.ipynb](./VGG_torch.ipynb)\n",
    "- Предварительный просмотр данных можно найти в [VGG_torch.ipynb](./VGG_torch.ipynb)\n",
    "\n",
    "В качетсве аугментаций ипользуется:\n",
    "- уменьшение картинки до разрешения 260*260\n",
    "- вырезка случайного квадрата размером 224*244 (сеть ожидает именно эту размерность)\n",
    "- переворот изображения по горизонтальной оси\n",
    "- нормализация"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import transforms, datasets\n",
    "\n",
    "train_transform = transforms.Compose([\n",
    "        transforms.Resize((260,260)),\n",
    "        transforms.RandomSizedCrop(224),\n",
    "#         transforms.ColorJitter(brightness=0.4, contrast=0.4, saturation=0.4, hue=0.2),\n",
    "#         transforms.RandomResizedCrop(224, scale=(0.08, 1.0), ratio=(0.75, 1.3333333333333333)),\n",
    "        transforms.RandomHorizontalFlip(.5),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                             std=[0.229, 0.224, 0.225])\n",
    "    ])\n",
    "test_transform = transforms.Compose([\n",
    "        transforms.Resize((224,224)),\n",
    "#         transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                             std=[0.229, 0.224, 0.225])\n",
    "    ])\n",
    "\n",
    "trainset = datasets.ImageFolder(root=dataset_path + '/train/', transform=train_transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size,\n",
    "                                          shuffle=True)\n",
    "testset = datasets.ImageFolder(root=dataset_path + '/val/', transform=test_transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, #batch_size=batch_size,\n",
    "                                         shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Создаем конструктор ResNet подобных сетей."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Выносим в функции сверточные слои для уменьшения количества букв в коде"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv1x1(in_channels, out_channels, stride=1):\n",
    "    return nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=stride, padding=0)\n",
    "\n",
    "def conv3x3(in_channels, out_channels, stride=1,padding=1):\n",
    "    return nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=stride, padding=padding)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Создаем ResNet блоки через классы.\n",
    "Класс NormalBlock собирает стандартный ResNet блок.<br>\n",
    "Класс BottleneckBlock собирает Bottleneck ResNet блок.\n",
    "\n",
    "Каждый класс ожидает параметры:\n",
    " - num_layer - порядковый номер слоя, в котором будет использоваться данных блок. В стандартной ResNet архитектуре ResNet блоки используются со второго слоя.\n",
    " - downsample - определяет тип downsampling'а.\n",
    "     - 0 - downsampling не используется\n",
    "     - 1 - downsampling используется в блоке, где уменьшается разрешение и увеличивается кол-во каналов\n",
    "     - -1 - downsampling используется в блоке, где разрешение не уменьшается, но увеличивается кол-во каналов (обычно последний слой)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NormalBlock(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        num_layer,\n",
    "        downsample = 0,\n",
    "        \n",
    "    ):\n",
    "        super(NormalBlock, self).__init__()\n",
    "        self.use_downsample = downsample\n",
    "        if num_layer == 2 and downsample == 1:\n",
    "            self.in_channels = 16*(2**num_layer)\n",
    "        elif num_layer > 2 and downsample != 0:\n",
    "            self.in_channels = 16*(2**(num_layer-1))\n",
    "        elif downsample == 0: \n",
    "            self.in_channels = 16*(2**num_layer)\n",
    "            \n",
    "        self.out_channels = 16*(2**num_layer)\n",
    "        \n",
    "        if downsample == 1:\n",
    "            self.downsample = nn.Sequential(\n",
    "                conv1x1(self.in_channels, self.out_channels, stride=2),\n",
    "                nn.BatchNorm2d(self.out_channels))\n",
    "            \n",
    "            self.conv1 = conv3x3(self.in_channels, self.out_channels, stride=2)\n",
    "            self.in_channels = self.out_channels\n",
    "            self.bn1 = nn.BatchNorm2d(self.out_channels)\n",
    "        elif downsample == -1:\n",
    "            self.downsample = nn.Sequential(\n",
    "                conv1x1(self.in_channels, self.out_channels, stride=1),\n",
    "                nn.BatchNorm2d(self.out_channels)\n",
    "                )\n",
    "            self.conv1 = conv3x3(self.in_channels, self.out_channels)\n",
    "            self.in_channels = self.out_channels\n",
    "            self.bn1 = nn.BatchNorm2d(self.out_channels)\n",
    "        elif downsample == 0:\n",
    "            self.conv1 = conv3x3(self.in_channels, self.out_channels)\n",
    "            self.in_channels = self.out_channels\n",
    "            self.bn1 = nn.BatchNorm2d(self.out_channels)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.conv2 = conv3x3(self.in_channels, self.out_channels)\n",
    "        self.bn2 = nn.BatchNorm2d(self.out_channels)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        skip = x\n",
    "#         print('Block input',x.shape)\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "#         print('Block before skip',out.shape)\n",
    "\n",
    "        if self.use_downsample != 0:\n",
    "#             print('Before downsample',out.shape, skip.shape)\n",
    "            skip = self.downsample(x)\n",
    "#             print('After downsample',out.shape, skip.shape)\n",
    "        out += skip\n",
    "        out = self.relu(out)\n",
    "\n",
    "        return out\n",
    "\n",
    "class BottleneckBlock(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        num_layer,\n",
    "        downsample = 0\n",
    "        \n",
    "    ):\n",
    "        super(BottleneckBlock, self).__init__()\n",
    "        \n",
    "        self.use_downsample = downsample\n",
    "        if num_layer == 2 and downsample == 1:\n",
    "            self.in_channels = 16*(2**num_layer)\n",
    "        elif num_layer > 2 and downsample != 0:\n",
    "            self.in_channels = 16*(2**(num_layer-1))*4\n",
    "        elif downsample == 0: \n",
    "            self.in_channels = 16*(2**num_layer)*4\n",
    "            \n",
    "        self.out_channels = 16*(2**num_layer)\n",
    "        \n",
    "        if downsample == 1:\n",
    "            self.downsample = nn.Sequential(\n",
    "                conv1x1(self.in_channels, self.out_channels*4, stride=2),\n",
    "                nn.BatchNorm2d(self.out_channels*4))\n",
    "            self.conv1 = conv1x1(self.in_channels, self.out_channels,stride=2)\n",
    "            self.in_channels = self.out_channels\n",
    "            self.bn1 = nn.BatchNorm2d(self.out_channels)\n",
    "        elif downsample == -1:\n",
    "            self.downsample = nn.Sequential(\n",
    "                conv1x1(self.in_channels, self.out_channels*4, stride=1),\n",
    "                nn.BatchNorm2d(self.out_channels*4))\n",
    "            self.conv1 = conv1x1(self.in_channels, self.out_channels)\n",
    "            self.in_channels = self.out_channels\n",
    "            self.bn1 = nn.BatchNorm2d(self.out_channels)\n",
    "        elif downsample == 0:\n",
    "            self.conv1 = conv1x1(self.in_channels, self.out_channels)\n",
    "            self.in_channels = self.out_channels\n",
    "            self.bn1 = nn.BatchNorm2d(self.out_channels)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.conv2 = conv3x3(self.in_channels, self.out_channels)\n",
    "        self.bn2 = nn.BatchNorm2d(self.out_channels)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.out_channels = 16*(2**num_layer)*4\n",
    "        self.conv3 = conv1x1(self.in_channels, self.out_channels)\n",
    "        self.bn3 = nn.BatchNorm2d(self.out_channels)\n",
    "        self.in_channels = self.out_channels\n",
    "        \n",
    "    def forward(self, x):\n",
    "        skip = x\n",
    "        \n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.conv3(out)\n",
    "        out = self.bn3(out)\n",
    "\n",
    "        if self.use_downsample != 0:\n",
    "#             print(out.shape, x.shape)\n",
    "            skip = self.downsample(x)\n",
    "#             print(out.shape, x.shape)\n",
    "        out += skip\n",
    "        out = self.relu(out)\n",
    "            \n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Класс конструктор ResNet подобных архитектур\n",
    "Данный класс создает готовую модель согласно гиперпараметрам, заданным в #resnet architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResNet_like(nn.Module):\n",
    "\n",
    "    def __init__(self, \n",
    "                 layers, \n",
    "                 num_classes,\n",
    "                 bottleneck,\n",
    "                 \n",
    "                 ):\n",
    "        \n",
    "        super(ResNet_like, self).__init__()\n",
    "        self.first = nn.Sequential(\n",
    "            nn.Conv2d(3, 64, kernel_size=7, stride=2, padding=3),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2, padding=1))\n",
    "        \n",
    "        self.body = nn.Sequential()\n",
    "        if bottleneck == True:\n",
    "            for num, layer in enumerate(layers):\n",
    "                for block in range(layer):\n",
    "                    if block == 0  and num < len(layers) - 1:\n",
    "                        downsample = 1\n",
    "                    elif block == 0 and num == len(layers) - 1:\n",
    "                        downsample = -1\n",
    "                    elif block != 0:  \n",
    "                        downsample = 0\n",
    "                    self.body.add_module(name='block_%d_%d'%(num+2,block+1), module=BottleneckBlock(num+2, downsample))\n",
    "        elif bottleneck == False:\n",
    "            for num, layer in enumerate(layers):\n",
    "                for block in range(layer):\n",
    "                    if block == 0  and num < len(layers) - 1:\n",
    "                        downsample = 1\n",
    "                    elif block == 0 and num == len(layers) - 1:\n",
    "                        downsample = -1\n",
    "                    elif block != 0:  \n",
    "                        downsample = 0\n",
    "                    self.body.add_module(name='block_%d_%d'%(num+2,block+1), module=NormalBlock(num+2, downsample))\n",
    "        \n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((1,1))\n",
    "        if bottleneck == True:\n",
    "            self.linear_input = 32*(2**(len(layers)))*4\n",
    "        else:\n",
    "            self.linear_input = 32*(2**(len(layers)))\n",
    "        self.linear = nn.Linear(self.linear_input, num_classes)\n",
    "        \n",
    "    def forward(self, x):\n",
    "\n",
    "        x = self.first(x)\n",
    "        x = self.body(x)\n",
    "#         print('Shape input avgpool:', x.shape)\n",
    "        x = self.avgpool(x)\n",
    "#         print('Shape input linear:', x.shape)\n",
    "        x = x.view(x.size(0), -1)\n",
    "#         print('Shape input linear:', x.shape)\n",
    "        x = self.linear(x)\n",
    "#         x = self.final(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Инициализируем модель с через конструктор. <br>\n",
    "Задаем оптимизаторы и создаем планировщик убывания скорости обучения"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ResNet_like(layers=resnet_layers, bottleneck=bottleneck, num_classes=num_classes)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "if optimizer_type == 'SGD':\n",
    "    optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate, weight_decay=0.0001, momentum=0.9)\n",
    "elif optimizer_type == 'Adam':\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate, betas=(0.9, 0.999), eps=1e-06, weight_decay=0.0001, amsgrad=False)\n",
    "\n",
    "if sheduler_type == 'step':\n",
    "    scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=num_epoch//sheduler_cycle, gamma=0.1)\n",
    "elif sheduler_type == 'cos':\n",
    "    scheduler = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, num_epoch//sheduler_cycle, eta_min=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ячейча используется для запуска реализации ResNet в библиотеке PyTorch для сравнения с конструктором."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from torchvision.models import resnet34\n",
    "# model = resnet34(num_classes=10)\n",
    "# criterion = nn.CrossEntropyLoss()\n",
    "# optimizer = torch.optim.SGD(model.parameters(), lr=0.learning_rate, momentum=0.9)\n",
    "# # optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate, betas=(0.9, 0.999), eps=1e-08, weight_decay=0, amsgrad=False)\n",
    "# # scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=40, gamma=0.1)\n",
    "# scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, num_epoch, eta_min=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Загружаем модель на видеокарту."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ResNet_like(\n",
       "  (first): Sequential(\n",
       "    (0): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3))\n",
       "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (body): Sequential(\n",
       "    (block_2_1): NormalBlock(\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 64, kernel_size=(1, 1), stride=(2, 2))\n",
       "        (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU()\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (block_2_2): NormalBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU()\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (block_3_1): NormalBlock(\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2))\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU()\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (block_3_2): NormalBlock(\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU()\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (block_4_1): NormalBlock(\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2))\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU()\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (block_4_2): NormalBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU()\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (block_5_1): NormalBlock(\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU()\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (block_5_2): NormalBlock(\n",
       "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU()\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (linear): Linear(in_features=512, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Создаем датафрейм для записи метрик обучения. <br>\n",
    "Датафрейм сохраняется в папку './metrics'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'./metrics/ResNet18_SGD_lr0.1_b32_cos_sc1.csv'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cols_name = ['epoch', 'time', 'current_lr', 'loss', 'accuracy_train', 'accuracy_val']\n",
    "metrics_frame = pd.DataFrame(columns=cols_name)\n",
    "metrics_frame_file = ('./metrics/' + model_name + '.csv')\n",
    "metrics_frame_file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Основной тренировочный цикл и подсчет метрик.\n",
    "    Основная метрика accuracy (топ1).\n",
    "    Метрика сохраняется в словарь и из словаря сохраняется в датасет и выводится на экран.\n",
    "    Лучшая мадель согласно валидации сохраняется на диск.\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1, Time: 115.04 sec, current_lr: 1.00e-01, Loss: 2.110, Accuracy_train: 0.251, Accuracy_val: 0.256\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(num_epoch):  # loop over the dataset multiple times\n",
    "\n",
    "    model.train()\n",
    "    start_time = time.time()\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "       \n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "#         inputs, labels = data\n",
    "#         print(data[1])\n",
    "        inputs, labels = data[0].to(device), data[1].to(device)\n",
    "#         print(labels)\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "       \n",
    "        # forward + backward + optimize\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "#         print('Loss: ', loss)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    scheduler.step()\n",
    "    \n",
    "    #Accuracy train and val\n",
    "    model.eval()\n",
    "    correct_train, correct_val = 0, 0\n",
    "    total_train, total_val = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in trainloader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            outputs = outputs.to(device)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total_train += labels.size(0)\n",
    "            correct_train += (predicted == labels).sum().item()\n",
    "        for images, labels in testloader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            outputs = outputs.to(device)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total_val += labels.size(0)\n",
    "            correct_val += (predicted == labels).sum().item()\n",
    "    end_time = time.time()\n",
    "    metrics = {'epoch': epoch+1,\n",
    "               'time': end_time - start_time,\n",
    "               'current_lr': [group['lr'] for group in optimizer.param_groups][0],\n",
    "               'loss': float(loss),\n",
    "               'accuracy_train': correct_train/total_train,\n",
    "               'accuracy_val': correct_val/total_val,\n",
    "               }\n",
    "\n",
    "    print(\"Epoch {}/{}, Time: {:.2f} sec, current_lr: {:.2e}, Loss: {:.3f}, Accuracy_train: {:.3f}, Accuracy_val: {:.3f}\".\n",
    "          format(metrics['epoch'], num_epoch, metrics['time'], metrics['current_lr'], metrics['loss'], metrics['accuracy_train'], metrics['accuracy_val']))\n",
    "    \n",
    "    metrics_frame = metrics_frame.append(pd.DataFrame.from_dict(metrics,orient='index').T)\n",
    "    metrics_frame.to_csv(metrics_frame_file,index=False)\n",
    "    \n",
    "    if save_best_model == True:\n",
    "        if metrics['accuracy_val'] == metrics_frame['accuracy_val'].max():\n",
    "            torch.save(model, save_model_dir + model_name + '.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Проверяем сохраненную модель на соответствие метрикам в порцессе обучения."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet_like(\n",
       "  (first): Sequential(\n",
       "    (0): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3))\n",
       "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (body): Sequential(\n",
       "    (block_2_1): NormalBlock(\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 64, kernel_size=(1, 1), stride=(2, 2))\n",
       "        (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU()\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (block_2_2): NormalBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU()\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (block_3_1): NormalBlock(\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2))\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU()\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (block_3_2): NormalBlock(\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU()\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (block_4_1): NormalBlock(\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2))\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU()\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (block_4_2): NormalBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU()\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (block_5_1): NormalBlock(\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU()\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (block_5_2): NormalBlock(\n",
       "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU()\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (linear): Linear(in_features=512, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = torch.load(save_model_dir + model_name + '.pt')\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy final model on the validation dataset is: 0.256\n"
     ]
    }
   ],
   "source": [
    "correct_train, correct_val = 0, 0\n",
    "total_train, total_val = 0, 0\n",
    "with torch.no_grad():\n",
    "    for images, labels in testloader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        outputs = model(images)\n",
    "        outputs = outputs.to(device)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total_val += labels.size(0)\n",
    "        correct_val += (predicted == labels).sum().item()\n",
    "        \n",
    "# print('Accuracy final model on validation dataset is: {:.3f})'.format(correct_val/total_val))\n",
    "print(f'Accuracy final model on the validation dataset is: {(correct_val/total_val):.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Известные проблемы:\n",
    "- в тренировочном цикле accuracy на тесте и валидации считается по всему датасету, что сильно увеличивает время обучения.\n",
    "- результат очень сильно зависит от стартового learning_rate. learning_rate для используемых оптимизаторов нужно выбирать в разном диапазоне (0,01-0,1 для SGD и 0,0005-0,03 для Adam), что приводит к некоторой путаницы\n",
    "- папки './model' и './metrics' должны быть созданы самостоятельно"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
